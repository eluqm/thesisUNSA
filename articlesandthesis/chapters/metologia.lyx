#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass extbook
\begin_preamble
\usepackage{algorithm,algpseudocode}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language spanish-mexico
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swedish
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Descripción del Modelo MEESN
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "MEESN"
description "Modelo Estocástico ESN"
literal "true"

\end_inset


\end_layout

\begin_layout Standard
El objetivo de este trabajo es proponer un modelo de proceso estocástico
 que puede ser aplicado en series temporales de comportamiento estocástico
 y también en series temporales de comportamiento periódico en sus propiedades
 probabilísticas, como; media, varianza, entre otras.
\end_layout

\begin_layout Standard
Nuestro modelo esta compuesto por dos componentes: 
\end_layout

\begin_layout Itemize

\series bold
Componente Estocástico:
\series default
 Presenta alguna variable aleatoria con distribución de probabilidad, es
 estocástico, en lugar de estadístico (probabilístico), para enfatizar la
 dependencia temporal de la variable 
\begin_inset CommandInset citation
LatexCommand citep
key "xu2002hydrologic"
literal "true"

\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
Componente Determinista:
\series default
 Donde las variables se consideran libres de variación aleatoria, de modo
 que no se considere que ninguna tenga una distribución de probabilidad
 
\begin_inset CommandInset citation
LatexCommand citep
key "xu2002hydrologic"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Standard
El modelo tiene la finalidad de generar escenarios de datos sintéticos hidrológi
cos, en términos de intervalos mensuales, para esto se utilizó una arquitectura
 basada en Redes Neuronales Recurrentes (RNAR) como el componente determinista;
 el uso de RNAR permite que nuestro modelo sea no-lineal capaz de capturar
 las características de una serie temporal sin la necesidad de realizar
 algún tipo de suposición a priori como retirar algunas características
 de tendencia o periodicidad.
 
\end_layout

\begin_layout Standard
El componente estocástico 
\begin_inset Formula $R_{t}$
\end_inset

, es la misma parte estocástica del modelo de 
\emph on
Thomas & Fiering
\emph default
.
 Los dos componentes se calculan sobre las series de tiempo normalizadas
 y estandarizadas.
 La forma final del modelo puede resumirse como la suma de ambos componentes,
 dada por la ecuación siguiente: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Y_{v,t}=f\left(R_{v,t}+E_{v,t}\right)\label{eq:eq_general}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde:
\end_layout

\begin_layout Itemize
\begin_inset Formula $Y_{v,t}$
\end_inset

, son los valores sintéticos producidos por el modelo, 
\end_layout

\begin_layout Itemize
\begin_inset Formula $E_{v,t}$
\end_inset

, son los valores producidos por la RNAR, 
\end_layout

\begin_layout Itemize
\begin_inset Formula $R_{v,t}$
\end_inset

, es el componente estocástico representado por las ecuaciones (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:randomCom"

\end_inset

).
\end_layout

\begin_layout Itemize
La función 
\begin_inset Formula $f$
\end_inset

 representa la inversa de las transformaciones de preprocesamiento.
\end_layout

\begin_layout Standard
Para que nuestro modelo pueda sintetizar series temporales como las de tipo
 hidrológicas(periódicas, estacionarias) con intervalos de tiempo mensuales,
 se tienen que ajustar los parámetros no sólo en intervalos de tiempo de
 la serie, si no también en su periodo.
 Por ejemplo, si el periodo es mensual, nuestro modelo estará compuesto
 por 12 componentes estocásticos.
 En ese caso el modelo es formado por un encadenamiento de sus componentes,
 entre el valor de entrada a la RNAR(componente determinista) y el siguiente
 periodo, como se puede observar en la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Esquema-del-proceso"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/eschema_model.pdf
	lyxscale 50
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Esquema-del-proceso"

\end_inset

Esquema del proceso estocástico propuesto, las esferas celestes y negras
 representan los componentes estocásticos y deterministas respectivamente,
 se produce un encadenamiento entre el valor de la serie temporal de un
 periodo que es parte de la entrada a la Red Recurrente del siguiente periodo.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Esta sección ofrece una visión general de nuestra propuesta de modelo de
 proceso estocástico, a continuación se realiza una descripción detallada
 de cada uno de sus componentes.
 
\end_layout

\begin_layout Section
Componente Estocástico
\end_layout

\begin_layout Standard
En términos de estadística, la variable 
\begin_inset Formula $R_{v,t}$
\end_inset

 representa un ruido aleatorio normalmente distribuido, que tiene en cuenta
 la incertidumbre que suele afectar a procesos hidrológicos.
 
\begin_inset Formula $R_{v,t}$
\end_inset

 se añade para proporcionar la variabilidad en 
\begin_inset Formula $Y_{v,t}$
\end_inset

 que permanece incluso después de que se conozca 
\begin_inset Formula $Y_{v,t-1}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "loucks2005water"
literal "true"

\end_inset

.
 Cada 
\begin_inset Formula $R_{v,t}$
\end_inset

 es independiente de valores pasados 
\begin_inset Formula $Y_{v,w}$
\end_inset

, donde 
\begin_inset Formula $w\leq t-1$
\end_inset

, y 
\begin_inset Formula $R_{v,t}$
\end_inset

 es independiente de 
\begin_inset Formula $R_{v,w}$
\end_inset

 para 
\begin_inset Formula $w\neq t-1$
\end_inset

.
 Como se señaló al principio, este componente es la misma parte estocástica
 del modelo de 
\emph on
Thomas & Fiering
\emph default
, por lo tanto, en la siguiente sección se examina dicho modelo y sus implicacio
nes en la formulación final de nuestra propuesta.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Claramente, "Qy1" se distribuirá normalmente si ambos "Qy" y "Vy" se distribuyen
 normalmente porque las sumas de variables aleatorias distribuidas normalmente
 independientes se distribuyen normalmente.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Proceso de Márkov de primer orden: modelo de Thomas & Fiering
\end_layout

\begin_layout Standard
En su forma más simple, el método consiste en el uso de doce ecuaciones
 de regresión lineal.
 Si, digamos, doce años de registro están disponibles, los datos como caudal/flu
jo de doce eneros y de los doce diciembres se abstraen y el valor de enero
 se calcula a partir del valor de diciembre; De manera similar, el valor
 de febrero se regula a partir del valor de enero, y así sucesivamente para
 cada mes del año, fíjese en la ecuación 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:thomas2"

\end_inset

.
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{multline}
\begin{aligned}Y_{enero}= & \overline{Y}_{enero}+b_{enero}\left(Y_{diciembre}-\overline{Y}_{diciembre}\right)+\varepsilon_{enero}\\
Y_{febrero}= & \overline{Y}_{febrero}+b_{febrero}\left(Y_{enero}-\overline{Y}_{enero}\right)+\varepsilon_{febrero}\\
...= & ...
\end{aligned}
\label{eq:thomas2}
\end{multline}

\end_inset


\end_layout

\begin_layout Standard
De la ecuación 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:thomas2"

\end_inset

, se desprende un análisis de regresión de 
\begin_inset Formula $Y_{t+1}$
\end_inset

en 
\begin_inset Formula $Y_{t}$
\end_inset

 sobre años de registros donde 
\begin_inset Formula $t=1,2,3,...,12$
\end_inset

(enero,febrero,...diciembre), 
\begin_inset Formula $b_{j}$
\end_inset

 es el coeficiente de regresión entre el mes 
\begin_inset Formula $t+1$
\end_inset

 y 
\begin_inset Formula $t$
\end_inset

.
 Los puntos de la linea de regresión mensual pueden determinarse de valores
 de meses previos, mediante la ecuación general:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\widehat{Y}_{t+1}=\overline{Y}_{t+1}+b_{t}\left(Y_{t}-\overline{Y}_{t}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
La variabilidad de estos puntos trazados desde la línea de regresión que
 reflejan la varianza sobre esta línea, es añadida por el componente adicional
 
\begin_inset Formula $R_{t}$
\end_inset

 (en rojo en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Random"

\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R_{t+1}=\epsilon\times\sigma_{t+1}\times\sqrt{\left(1-r_{t}^{2}\right)}\label{eq:randomCom}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma_{t+1}$
\end_inset

, es la desviación estándar en el mes 
\begin_inset Formula $t+1$
\end_inset

 .
\end_layout

\begin_layout Itemize
\begin_inset Formula $r_{t}$
\end_inset

, es el coeficiente de correlación entre los meses 
\begin_inset Formula $t+1$
\end_inset

 y 
\begin_inset Formula $t$
\end_inset

 (en todo el registro histórico).
 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\epsilon=N(0,1)$
\end_inset

, un ruido aleatorio normalmente distribuido con media cero y desviación
 estándar uno.
 
\begin_inset Note Note
status collapsed

\begin_layout Itemize
\begin_inset Formula $\overline{Y}_{t}=\frac{1}{n}\sum_{t}Y_{t,v}$
\end_inset

,
\begin_inset Formula $\left(v=t,12+t,24+t,...\right)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma_{t}=\sqrt{\frac{\sum_{v}\left(Y_{t,v}-\overline{Y}_{t}\right)^{2}}{n-1}}$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $r_{t}=\frac{\sum_{v=1}\left(Y_{t,v}-\overline{Y}_{t}\right)\left(Y_{t+1,v}-\overline{Y}_{t+1}\right)}{\sqrt{\sum_{v}\left(Y_{t,v}-\overline{Y}_{t}\right)^{2}\sum_{v}\left(Y_{t+1,v}-\overline{Y}_{t+1}\right)^{2}}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/thomas_fiering_random_es.pdf
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Random"

\end_inset

Distribución condicional de 
\begin_inset Formula $Y_{t+1}$
\end_inset

 dada 
\begin_inset Formula $Y_{t}=y_{t}$
\end_inset

 para dos variables aleatorias normales.
 El óvalo rojo representa el componente estocástico utilizado por nuestro
 modelo en su forma final.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
El procedimiento para utilizar el componente estocástico 
\begin_inset Formula $R_{t}$
\end_inset

 en nuestro modelo se describe en pseudocódigo 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:ramdom_component"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
caption{Calcular Componente Aleatorio $R_{t}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$
\backslash
textit{n} 
\backslash
gets 
\backslash
text{length of }
\backslash
textit{(registro historico)}$}
\end_layout

\begin_layout Plain Layout


\backslash
For{$t= 0 
\backslash
to 11 $}
\backslash
Comment{mensual, t:=0,enero} 
\end_layout

\begin_layout Plain Layout


\backslash
State $v
\backslash
gets t$
\end_layout

\begin_layout Plain Layout


\backslash
State $j
\backslash
gets 1$
\end_layout

\begin_layout Plain Layout


\backslash
State $sum_{t}
\backslash
gets 0, sum_{t+1}
\backslash
gets 0$
\end_layout

\begin_layout Plain Layout


\backslash
While{$v 
\backslash
le n$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $sum_{t}
\backslash
gets sum_{t}+Y_{t,v}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $sum_{t+1}
\backslash
gets sum_{t+1}+Y_{t+1,v}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets j+1, v
\backslash
gets v+12*j$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
overline{Y}_{t}=
\backslash
frac{sum_{t}}{n}$}
\backslash
Comment{caudal medio}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
overline{Y}_{t+1}=
\backslash
frac{sum_{t+1}}{n}$}
\backslash
Comment{caudal medio}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets 1, v
\backslash
gets t$
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout


\backslash
While{$v 
\backslash
le n$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp1_{t}
\backslash
gets temp1_{t} + 
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp2_{t}
\backslash
gets temp2_{t} + 
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)^{2}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp1_{t+1}
\backslash
gets temp1_{t+1} + 
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)$	
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp2_{t+1}
\backslash
gets temp2_{t+1} + 
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)^{2}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets j+1, v
\backslash
gets v+12*j$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State{$
\backslash
sigma_{t}=
\backslash
sqrt{
\backslash
frac{
\backslash
left(temp2_{t}
\backslash
right)}{n-1}}$}
\backslash
Comment{desviación standard} 
\end_layout

\begin_layout Plain Layout


\backslash
State{$r_{t}=
\backslash
frac{
\backslash
left(temp1_{t}
\backslash
right)
\backslash
times 
\backslash
left(temp1_{t+1}
\backslash
right)}{
\backslash
sqrt{
\backslash
left(temp2_{t}
\backslash
right) 
\backslash
times 
\backslash
left(temp2_{t+1}
\backslash
right)}}$}
\backslash
Comment{coeficiente de correlación entre meses $t$ y $t+1$} 
\end_layout

\begin_layout Plain Layout


\backslash
State{$
\backslash
epsilon=N(0,1)$} 
\backslash
Comment{ruido aleatorio normalmente distribuido}
\end_layout

\begin_layout Plain Layout


\backslash
State{$R_{t+1}=
\backslash
epsilon
\backslash
times
\backslash
sigma_{t+1}
\backslash
times
\backslash
sqrt{
\backslash
left(1-r_{t}^{2}
\backslash
right)}$}
\backslash
Comment{Componente estocástico, El modelo es entonces un conjunto de doce
 ecuaciones de regresión}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:ramdom_component"

\end_inset

Calcular Componente Aleatorio
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Finalmente para generar series de tiempo sintéticas se repite el procedimiento,
 generando una secuencia de números aleatorios 
\begin_inset Formula $\left\{ \epsilon_{1},\epsilon_{2},...\right\} $
\end_inset

 que se sustituyen en el modelo.
 
\end_layout

\begin_layout Standard
En este trabajo se usó una topología recurrente de Redes Neuronales(RNAR)
 como componente determinista, pero el modelo propuesto no se limita sólo
 a ese tipo de Redes neuronales.
 Pueden usarse otras arquitecturas de RNA en su lugar.
 Las razones de la elección de RNAR para generación de series temporales
 en este trabajo se abordan a continuación.
 
\end_layout

\begin_layout Section
Componente Determinista
\end_layout

\begin_layout Standard
Conforme a lo anterior, las Redes Neuronales Recurrentes(RNAR) se distinguen
 de las redes 
\emph on
feedforward
\emph default
 por presentar 
\series bold
bucles 
\series default
de retroalimentación, creando así una memoria interna que es requerida para
 almacenar la historia de los patrones de entrada.
 La adición de memoria en las RNAR's tiene un propósito: extraer información
 de las secuencias mismas(series temporales) y utilizarlas para realizar
 tareas que las redes de 
\emph on
feedforward
\emph default
 no pueden.
 
\end_layout

\begin_layout Standard
Esa información secuencial es preservada en los 
\series bold
\emph on
estados internos ó unidades de procesamiento(PEs
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "PEs"
description "Unidades de Procesamiento\\\\"
literal "true"

\end_inset

)
\series default
\emph default
 de la RNAR, y permite manejar valores en el tiempo 
\begin_inset Formula $t$
\end_inset

 sin la necesidad de un pre-procesamiento o retraso de lineas.
 Por lo tanto, nuestro modelo es clasificado como uno auto-regresivo, ya
 que las entradas utilizan valores pasados de la serie temporal, como se
 puede ver en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Generación-de-escenarios"

\end_inset

.
 
\end_layout

\begin_layout Standard
A fin de obtener un determinado valor para la serie en el instante de tiempo
 
\begin_inset Formula $t$
\end_inset

, en nuestro modelo la RNAR recibe como entrada los valores en el instante
 de tiempo 
\begin_inset Formula $t-1$
\end_inset

.
 La estructura en detalle de la red neuronal recurrente de tiempo discreto
 aplicada en este trabajo es presentada en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:EsquemaRNN"

\end_inset

, donde el valor de la unidad de entrada en 
\begin_inset Formula $t$
\end_inset

 es 
\begin_inset Formula $y_{t}$
\end_inset

, las PEs o 
\series bold
\emph on
echo states
\series default
\emph default
 son representadas por 
\begin_inset Formula $x\left(t\right)$
\end_inset

, y las unidades de salida por 
\begin_inset Formula $E_{t+1}$
\end_inset

.
 La activación de los PEs internos (echo states) se actualiza de acuerdo
 con:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x\left(t+1\right)=\vartheta\left(W^{in}y_{t+1}+\theta_{t+1}+Wx(t)\right)\label{eq:statesRNN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde:
\end_layout

\begin_layout Itemize
\begin_inset Formula $x(t)$
\end_inset

, es el vector de estados internos ó PEs.
\end_layout

\begin_layout Itemize
\begin_inset Formula $W$
\end_inset

, es la matriz de pesos sinápticos con conexión recurrente.
\end_layout

\begin_layout Itemize
\begin_inset Formula $y_{t+1}$
\end_inset

, es la señal de entrada, en el mes 
\begin_inset Formula $t+1$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $W^{in}$
\end_inset

, es la matriz de pesos sinápticos entre la señal de entrada y los PEs.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\vartheta$
\end_inset

, representa la función de activación de los estados internos(usualmente
 una función tangente hiperbólica).
\end_layout

\begin_layout Itemize
\begin_inset Formula $\theta_{t+1}$
\end_inset

, bias.
\end_layout

\begin_layout Standard
La salida de la RNAR es calculada de acuerdo a la ecuación:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{t+1}=\delta\left(W^{out}\left(x(t+1)+y_{t}\right)+\theta_{t}\right)\label{eq:ouputRNN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde: 
\begin_inset Formula $W^{out}$
\end_inset

, es la matriz de pesos entre los estados internos 
\begin_inset Formula $x(t+1)$
\end_inset

 sumado a las señales de entrada 
\begin_inset Formula $y_{t}$
\end_inset

 y las neuronas de salida.
 
\begin_inset Formula $\delta$
\end_inset

 es la función de activación de las neuronas de salida, esta es una herramienta
 estándar para condensar valores muy pequeños o muy grandes dentro de un
 espacio logístico.
\end_layout

\begin_layout Standard
Como se puede observar en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Esquema-del-proceso"

\end_inset

, Los valores sintéticos 
\begin_inset Formula $Y_{t}$
\end_inset

 de una serie temporal en 
\begin_inset Formula $t$
\end_inset

 es dada por la suma de la salida de nuestra RNAR(
\begin_inset Formula $E_{t}$
\end_inset

), y la parte estocástica del modelo de 
\emph on
Thomas & Fiering
\emph default
(
\begin_inset Formula $R_{t}$
\end_inset

), descrita por la ecuación 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq_general"

\end_inset

.
 Con el fin de obtener una descripción matemática, se concatenan las ecuaciones
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:statesRNN"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ouputRNN"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq_general"

\end_inset

, para obtener la siguiente ecuación extendida de nuestro modelo: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{multline}
\begin{aligned}Y_{t+1}= & f\left(\delta\left(W^{out}\times\left(\vartheta\left[W^{in}y_{t}+\theta_{t}+Wx(t-1)\right]+y_{t}\right)+\theta_{t}\right)+R_{t}\right)\end{aligned}
\label{eq:final_form}
\end{multline}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/RNN_schema.pdf
	lyxscale 50
	scale 21

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:EsquemaRNN"

\end_inset

Esquema detallado de unidades internas (neuronas) de una Red Neuronal Recurrente
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Conforme a lo mencionado en secciones anteriores, ocurre un encadenamiento
 de componentes, entre el valor de entrada a la RNAR(
\begin_inset Formula $Y_{t+1}$
\end_inset

) y el siguiente periodo, es decir, cada término generado 
\begin_inset Formula $Y_{t}$
\end_inset

 de una serie temporal sintética se obtiene a partir del valor anterior
 
\begin_inset Formula $Y_{t-1}$
\end_inset

, como se puede observar en la figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Esquema-del-proceso"

\end_inset

.
 Esta información secuencial es preservada en los estados internos de la
 RNAR(
\begin_inset Formula $x(t)$
\end_inset

) que permiten abarcar muchos pasos en el tiempo como cascadas para afectar
 el procesamiento de cada nueva entrada.
 Por lo tanto, no es necesario incorporar técnicas de 
\begin_inset Quotes sld
\end_inset

ventana
\begin_inset Quotes srd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Vafaeipour2014"
literal "true"

\end_inset

 en nuestro modelo, en contraste con trabajos similares en la literatura
 
\begin_inset CommandInset citation
LatexCommand citep
key "lcdcampos,Awchi,herrera2013modelo"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Standard
A menudo el uso de Redes Neuronales implica la tarea de estimar un gran
 número de parámetros, relacionados a su estructura y desempeño.
 En este trabajo se utiliza un caso especial de RNAR-esn que fue desarrollado
 bajo el nombre de 
\emph on
Reservoir Computing
\emph default
(RC), específicamente se usa el método 
\emph on
llamado Echo State Network(ESN) 
\begin_inset CommandInset citation
LatexCommand citep
key "Jaeger2001a"
literal "true"

\end_inset

.
 
\emph default
Es evidente que para generar series sintéticas es preciso ajustar nuestro
 modelo con la serie temporal histórica.
 Podemos formalizar dicho problema como:
\end_layout

\begin_layout Subsection
Formalización de los parámetros
\end_layout

\begin_layout Standard
Dada una serie temporal 
\begin_inset Formula $Y_{1},Y_{2},...,Y_{t}$
\end_inset

 cada uno en un espacio real 
\begin_inset Formula $N_{Y}$
\end_inset

-dimensional, el objetivo consiste en calcular una maquina de aprendizaje
 
\begin_inset Formula $\varphi\left(\bullet,p\right)$
\end_inset

 con 
\begin_inset Formula $p$
\end_inset

 parámetros tales que sea capaz de predecir (mejor posible) el valor de
 cualquier observación de 
\begin_inset Formula $Y_{t+\tau}\left(\tau\geq1\right)$
\end_inset

.
 La función objetivo asociada a 
\begin_inset Formula $\varphi\left(\bullet,p\right)$
\end_inset

 para una sola tupla 
\begin_inset Formula $\left(\varphi\left(Y_{t},p\right),Y_{t+\tau}\right)$
\end_inset

, está definida por una función de distancia que mide la desviación entre
 el objetivo 
\begin_inset Formula $Y_{t+\tau}$
\end_inset

 y la predicción 
\begin_inset Formula $\varphi\left(Y_{t},p\right)$
\end_inset

.
 En este trabajo se utiliza la distancia de Error Cuadrático Medio Normalizado
 para un rango arbitrario de tiempo 
\begin_inset Formula $\tau$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
NRMSE=\sqrt{\frac{1}{\sigma\left(Y_{\tau}\right)\tau}\sum_{t=1}^{\tau}\sum_{i=1}^{N_{Y}}\left(\varphi_{i}\left(Y_{t},p\right)-Y_{i,\left(t+\tau\right)}\right)^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Parámetros de ESN
\end_layout

\begin_layout Standard
Las Redes ESN tienen algunos parámetros globales que impactan en su rendimiento.
 En este trabajo la configuración de ESN básicamente depende de los siguientes
 parámetros: el tamaño del reservorio(estados internos), el radio espectral
 de la matriz del reservorio, la densidad de la matriz del reservorio y
 la topología de la red del reservorio(conectividad) 
\begin_inset CommandInset citation
LatexCommand citep
key "LukoseviciusJaeger09,Baserrech2015"
literal "true"

\end_inset

.
 Decidimos explicar con más detalle los tres más comunes a todas las arquitectur
as y enfoques de aprendizaje en la literatura ESN.
\end_layout

\begin_layout Subsubsection
Tamaño del reservorio 
\end_layout

\begin_layout Standard
Según 
\begin_inset CommandInset citation
LatexCommand citet
key "Jaeger2001a"
literal "true"

\end_inset

, un parámetro obviamente crucial del modelo 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq_general"

\end_inset

 es 
\begin_inset Formula $N_{x}$
\end_inset

, el número de unidades en el reservorio.
 Se sabe que cuanto más grande sea el reservorio, mejor será el rendimiento,
 siempre y cuando se tomen las medidas de regularización apropiadas contra
 el 
\emph on
overfitting
\emph default
.
 Cuanto más grande sea el espacio de las señales del reservorio 
\begin_inset Formula $x(t)$
\end_inset

, más fácil será encontrar una combinación lineal de las señales para aproximar
 
\begin_inset Formula $y^{objetivo}(t)$
\end_inset

.
\end_layout

\begin_layout Standard
Dado que el entrenamiento y la ejecución de un ESN es computacionalmente
 barato en comparación con otros enfoques RNAR, los tamaños del reservorio
 de orden 
\begin_inset Formula $10^{4}$
\end_inset

 son comunes 
\begin_inset CommandInset citation
LatexCommand citep
key "Alomar:2016:FSE:2934357.2934372"
literal "true"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Radio Espectral
\end_layout

\begin_layout Standard
Básicamente el radio espectral controla la estabilidad y tiene impacto en
 la capacidad de memoria del modelo.
 El radio espectral de 
\begin_inset Formula $W$
\end_inset

, lo denotamos por 
\begin_inset Formula $\rho\left(W\right)$
\end_inset

.
 Si 
\begin_inset Formula $\rho\left(W\right)$
\end_inset

 es menor que 1, se puede asegurar la estabilidad del ESN 
\begin_inset CommandInset citation
LatexCommand citep
key "LukoseviciusJaeger09"
literal "true"

\end_inset

.
 Para satisfacer esta condición, la matriz 
\begin_inset Formula $W$
\end_inset

 se suele escalar de la siguiente manera: 
\begin_inset Formula $W\leftarrow\left(\frac{\alpha}{\rho\left(W\right)}\right)W$
\end_inset

, donde 
\begin_inset Formula $\alpha$
\end_inset

 es una constante en 
\begin_inset Formula $<0,1]$
\end_inset

.
 Un radio espectral 
\begin_inset Formula $\rho\left(W\right)$
\end_inset

 cercano a 1 es apropiado para tareas de aprendizaje que requieren tiempos
 largos.
 Por otro lado, un valor de 
\begin_inset Formula $\rho\left(W\right)$
\end_inset

 cerca de 0 es adecuado para las tareas que requieren memoria corta 
\begin_inset CommandInset citation
LatexCommand citep
key "Verstraeten2007391"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Conectividad y Topología 
\end_layout

\begin_layout Standard
Para 
\begin_inset CommandInset citation
LatexCommand citet
key "Song:2010:ECS:1801020.1801314"
literal "true"

\end_inset

 y 
\begin_inset CommandInset citation
LatexCommand citet
key "Jaeger78"
literal "true"

\end_inset

, la conectividad es otro parámetro importante en el diseño de una buena
 red ESN.
 Especialmente si se consideran todas las arquitecturas posibles.
 La conectividad se define como el número de pesos distintos de cero del
 número total de pesos en la red (por ejemplo si tenemos 10 neuronas internas,
 tendremos 100 pesos, si ponemos la conectividad a 0.6 entonces el número
 de pesos en 0's serán 
\begin_inset Formula $0.4\times100=40$
\end_inset

).
 En el caso en que se consideren matrices de peso ortonormal, la conectividad
 parece ser uno de los parámetros críticos que definen el espacio de la
 solución.
 Según 
\begin_inset CommandInset citation
LatexCommand citet
key "Millea2014"
literal "true"

\end_inset

, esto ocurre sólo para un ESN lineal.
 En el caso no lineal, es decir, cuando se utiliza una función de activación
 
\emph on

\begin_inset Formula $tanh$
\end_inset


\emph default
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:statesRNN"

\end_inset

, algunos investigadores han informado de ningún efecto del valor de conectivida
d 
\begin_inset CommandInset citation
LatexCommand citep
key "Koryakin201235"
literal "true"

\end_inset

.
\end_layout

\begin_layout Standard
La topología del reservorio también puede impactar en el rendimiento del
 modelo.
 Con frecuencia, los pesos se inicializan utilizando una distribución uniforme
 en un rango arbitrario.
 Se han estudiado varios enfoques para encontrar mejores pesos de reservorio
 que los pesos aleatorios.
 Enfoques que utilizan mapas topográficos, optimización de enjambres se
 pueden ver en 
\begin_inset CommandInset citation
LatexCommand citep
key "BasterrechAlba,BasterrechFyfe"
literal "true"

\end_inset

.
 Pero, el enfoque más común sigue utilizando la 
\series bold
inicialización aleatoria
\series default
 
\begin_inset CommandInset citation
LatexCommand citep
key "Baserrech2015"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Standard
Finalmente, con respeto a la conectividad, cabe indicar que en este trabajo
 usamos ESN's no lineales (
\series bold
\emph on

\begin_inset Formula $tanh$
\end_inset


\series default
\emph default
 como función de activación de las neuronas).
 Basados en los estudios de 
\begin_inset CommandInset citation
LatexCommand citet
key "Jaeger78"
literal "true"

\end_inset

 y 
\begin_inset CommandInset citation
LatexCommand citet
key "Millea2014"
literal "true"

\end_inset

, sabemos que en la práctica a menudo se utiliza alrededor del 20% de valores
 distintos de cero 
\begin_inset CommandInset citation
LatexCommand citep
key "LukoseviciusJaeger09"
literal "true"

\end_inset

, para definir las matrices del reservorio, esto debido a que el costo computaci
onal del procesamiento de matrices densas es mayor al costo de procesamiento
 de matrices 
\emph on
esparsa
\emph default
.
 Por lo tanto y basados un estudio preliminar, se consideró la 
\series bold
inicialización aleatoria
\series default
 del reservorio y 
\series bold
conectividad
\series default
 del 20% como enfoque estándar para inicializar los pesos de nuestro componente
 determinista.
 
\end_layout

\begin_layout Standard
Con el fin de encontrar una buena configuración de ESN para nuestro modelo,
 empleamos un método computacional(Optimización aleatoria) muy sencillo,
 en la que la conectividad no es considerada, solamente el tamaño del reservorio
 y el radio espectral.
\end_layout

\begin_layout Subsubsection
Optimización aleatoria
\begin_inset CommandInset label
LatexCommand label
name "subsec:Optimización-aleatoria"

\end_inset


\end_layout

\begin_layout Standard
Hemos utilizado la optimización aleatoria 
\begin_inset CommandInset citation
LatexCommand citep
key "matyas1965random"
literal "true"

\end_inset

, para encontrar los mejores parámetros y mejorar el rendimiento de la red.
 Como resultado de que, al evaluar un ESN pequeño toma muy poco tiempo,
 unos pocos cientos de milisegundos con 3000 pasos de entrenamiento.
 Así que realizamos experimentos de Monte Carlo en los cuales en cada repetición
 uno (o más) los pesos se cambian al azar y si da un error menor, entonces
 el peso se guarda, de lo contrario no.
 Este es un algoritmo muy simple que dio muy buenos resultados cuando se
 probó en las series hidrológicas temporales de MOPEX 
\begin_inset CommandInset citation
LatexCommand citep
key "Duan20063"
literal "true"

\end_inset

.
 Podemos ver el pseudo-código del algoritmo en 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:parametros"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
caption{Optimización aleatoria $R_{t}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$N_{x} 
\backslash
gets reservorio_{size}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$
\backslash
alpha 
\backslash
gets <0,1]$}  
\end_layout

\begin_layout Plain Layout


\backslash
State {$W_{1}
\backslash
gets MatrizEsparsa, i 
\backslash
gets 0$} 
\backslash
Comment{esparsa con $20
\backslash
%$ conectividad} 
\end_layout

\begin_layout Plain Layout


\backslash
While{$i 
\backslash
le iteraciones$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$W
\backslash
gets W_{1}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$wr
\backslash
gets pesos-aleatorios$}
\end_layout

\begin_layout Plain Layout


\backslash
For{$j = 1 
\backslash
to repeticiones $}
\end_layout

\begin_layout Plain Layout


\backslash
State {reemplazar$W(wr)$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$error_{actual} 
\backslash
gets error_{get}(
\backslash
varphi
\backslash
left(
\backslash
bullet,W,
\backslash
alpha,N_{x}
\backslash
right))$}
\end_layout

\begin_layout Plain Layout


\backslash
If{$error_{actual} 
\backslash
le error_{min}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$W_{1} 
\backslash
gets W$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$error_{min} 
\backslash
gets error_{actual}$}
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout


\backslash
State {$i
\backslash
gets i+1$}
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:parametros"

\end_inset

Optimización Aleatoria
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
El aumento del número de las ESN en 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:parametros"

\end_inset

 no significa ningún aumento sustancial en las demandas computacionales,
 ya que todo el proceso de formación ESN es sólo el cálculo de una matriz
 pseudo inversa
\begin_inset CommandInset citation
LatexCommand citep
key "Kuna2015"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Standard
Una vez ajustados los parámetros 
\begin_inset Formula $p$
\end_inset

 del componente determinista, es posible generar diferentes escenarios de
 una serie temporal analizada.
 
\end_layout

\begin_layout Section
Generación de Escenarios
\end_layout

\begin_layout Standard
El modelo propuesto es un modelo mixto estocástico determinista para la
 generación de datos sintéticos que debe capturar el comportamiento estocástico
 de los registros históricos, por lo tanto debe ser capaz de generar series
 sintéticas temporales igualmente probables con la serie histórica.
 Para hacer esto posible, es necesario usar los primeros valores de los
 términos auto-regresivos que son obtenidos de las series históricas.
\end_layout

\begin_layout Standard
La Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Generación-de-escenarios"

\end_inset

 ilustra el diagrama detallado de nuestro modelo en la generación de escenarios.
 Un valor de la serie se obtiene por la concatenación de valores anteriores(bloq
ues verdes en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Generación-de-escenarios"

\end_inset

).
 Se puede definir el número de años 
\begin_inset Formula $n$
\end_inset

 a ser generado, en cada instante de tiempo 
\begin_inset Formula $t=\left(1,2,...,n\times12\right)$
\end_inset

 en la ecuación 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:final_form"

\end_inset

.
\end_layout

\begin_layout Section
Consideraciones Finales
\end_layout

\begin_layout Standard
En este informe tratamos de dar una visión detallada del modelo propuesto
 por nuestro trabajo.
 Se pueden obtener reflexiones teóricas sobre el funcionamiento interno
 de los componentes de nuestra propuesta.
 Primero se resalta la necesidad de una incertidumbre que suele afectar
 a procesos naturales hidrológicos, esta característica es proporcionada
 por el componente estocástico.
 Seguidamente, se explica un caso especial de Redes Neuronales Recurrentes(ESN),
 que tienen la capacidad de tener memoria interna resultante de sus conexiones
 de retroalimentación, característica muy potente en la literatura de redes
 neuronales.
 También se fundamenta las razones de optimizar 2 parámetros (radio espectral
 y tamaño del reservorio) por encima de otros en el diseño de ESN.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset listings
lstparams "basicstyle={\footnotesize},escapeinside={(*@}{@*)}"
inline false
status open

\begin_layout Plain Layout

(1) Para cada mes, t=1,2,3 ...
 12, calcular
\end_layout

\begin_layout Plain Layout

	(a) El caudal medio 
\end_layout

\begin_layout Plain Layout

		(*@  @*)
\end_layout

\begin_layout Plain Layout

	(b) La desviación estandar 
\end_layout

\begin_layout Plain Layout

		(*@ $
\backslash
sigma_{t}=
\backslash
sqrt{
\backslash
frac{
\backslash
sum_{v}
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)^{2}}{n-1}}$  @*)
\end_layout

\begin_layout Plain Layout

	(c) El coeficiente de correlación considerando el caudal en el mes anterior
\end_layout

\begin_layout Plain Layout

		(*@ $r_{t}=
\backslash
frac{
\backslash
sum_{v=1}
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)}{
\backslash
sqrt{
\backslash
sum_{v}
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)^{2}
\backslash
sum_{v}
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)^{2}}}$ @*)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/propose_model-as-ES.pdf
	lyxscale 7
	scale 4.7

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Generación-de-escenarios"

\end_inset

Generación de escenarios sintéticos, se observa en detalle el nuevo modelo
 
\series bold
MEESN
\series default
 en este trabajo.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_body
\end_document
