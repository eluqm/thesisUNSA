#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass elsarticle
\begin_preamble
\usepackage{color}
\usepackage{algorithm,algpseudocode}
\usepackage{tikz}
\usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}
\definecolor{maroon}{rgb}{0.5,0,0}
\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{orangered}{RGB}{239,134,64}
\definecolor{orchid}{RGB}{218,112,214}
\definecolor{violet}{RGB}{238,130,238}
\tnotetext[t1]{This document is a collaborative effort.}
%\tnotetext[t2]{The second title footnote which is a longer
%longer than the first one and with an intention to fill
%in up more than one line while formatting.}
%\author[rvt]{E.F.~Luque\corref{cor1}\fnref{fn1}}
%\ead{edluquem@usp.br.com}
\author[rvt,rvt2]{E.F.~Luque}
\ead{edluquem@usp.br.com}
\author[focal]{D.L.~Rubin}
\ead{dlrubin@stanford.edu}
\author[rvt]{D.A.~Moreira}
\ead{dilvan@gmail.com}


%\ead[url]{http://www.elsevier.com}
%\cortext[cor1]{Corresponding author}
%\cortext[cor2]{Principal corresponding author}
%\fntext[fn1]{This is the specimen author footnote.}
%\fntext[fn2]{Another author footnote, but a little more
%longer.}
%\fntext[fn3]{Yet another author footnote. Indeed, you can have
%any number of author footnotes.}

\address[rvt]{Department of Computer Science\\ University of São Paulo\\ São Carlos, Brazil}
\address[rvt2]{Department of Computer Science\\ National University of San Agustin\\ Arequipa, Peru}
\address[focal]{Department of Radiology\\ Stanford University\\ Stanford, USA\\}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frontmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
title{aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{abstract}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

The stochastic streamflow models (SSMS) are time series models for precise
 prediction of hydrological data.
 They could generate ensembles of synthetic time series traces useful for
 hydrologic risk management.
 Nowadays, deep learning networks get many considerations in time series
 prediction.
 However, despite their theoretical benefits, they fail due to their architectur
e, defects of the backpropagation method, such as  slow convergence and
 the vanishing gradient problem.
 In order to cover these requirements, we propose a new stochastic model
 applied in problems that involve phenomena of stochastic behavior and periodic
 characteristics.
 In the new model two components were used, the first one, a type of recurrent
 neural network embedding an echo-state (ESN) learning mechanisn instead
 of conventional back-propagation method, an interesting feature of ESN
 is that from certain algebraic properties, training only the output of
 the network is often sufficient to achieve excellent performance in practical
 applications.
 The last part consists of the uncertainty associated with stationary processes,
 the model is finally called stochastic streamflow models ESN (SSNESN).
 This model was calibrated with time series of monthly discharge data from
  different river basins of MOPEX data set.
 We interpret our expetimental findings by comparison with two feedforward
 neural networks and the traditional Thomas–Fiering model.
 The results show that the SSNESN can achieve a significant enhancement
 in the prediction performance, learning speed, and short-term memory capacity,
 with interesting potential in the context of hydrometeorological resources.
 This model, along with their simplicity and ease of training, can be considered
 a first attempt that applies the echo state network methodology to stochastic
 process.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{abstract}
\end_layout

\begin_layout Plain Layout


\backslash
begin{keyword}
\end_layout

\begin_layout Plain Layout

ESN, Recurrent, Stochastic process, Neural Network, streamflow.s
\end_layout

\begin_layout Plain Layout


\backslash
end{keyword}
\end_layout

\begin_layout Plain Layout


\backslash
end{frontmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In probability theory an stochastic process is defined as a set of models
 that allow the study of problems with random components.
 Observing a phenomenon with random characteristics for a period of time,
 it is possible to obtain a trajectory of this observed process.
 When carrying out the same observation in a different period of time it
 is possible to obtain another trajectory, different from the first one.
 Thus, stochastic process corresponds to the set of all possible trajectories
 that can be observed of this phenomenon.
 Each trajectory are called a time series.
 Therefore, time series is considered one realization of stochastic process.
\end_layout

\begin_layout Standard
Natural phenomena such as precipitation and streamflow discharge have nonlinear,
 complex and chaotic characteristics.
 In order to model the behavior of these phenomena, initially linear approximati
on was used 
\begin_inset CommandInset citation
LatexCommand cite
key "BOXANDJenKys"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LUNA2006"

\end_inset

.
 Afterwards, were developed methods using self-correcting models such as
 the PAR(p) model 
\begin_inset CommandInset citation
LatexCommand cite
key "maceira2,lcdcampos"

\end_inset

.
 However, these models are statistical and linear, which means that their
 application in time series of chaotic behavior such as hydrometeorological
 series, cannot capture real characteristics of this time series being sometimes
 inadequate 
\begin_inset CommandInset citation
LatexCommand cite
key "Raman95multivariatemodelling"

\end_inset

.
\end_layout

\begin_layout Standard
Currently, among the approaches that attempt to model complex non-linear
 behavior that can be adequate to deal with such problems, we have the deep
 learning approach 
\begin_inset CommandInset citation
LatexCommand cite
key "YU2015308"

\end_inset

, this approach exerts fascination on researchers due their hierarchical
 representations from data.
 In fact, this approach have been widely used in most research and applications
 in forecasting models from simplest Artificial Neural Networks (ANN) feedforwar
d to the most complex architecture based on many layers, each of which be
 expressed by feature detector units.
 In general, ANNs feedforward have been widely used in most research and
 applications in forecasting models in contrast to Recurrent Neural Networks(RNN
)
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

.
 The RNN's are able to represent dynamic non-linear maps commonly found
 in time series forecasting tasks
\begin_inset CommandInset citation
LatexCommand cite
key "lcdcampos"

\end_inset

.Studies about the performance in forecasting, demonstrate that RNN are better
 than their peers ANN, in virtually all tests
\begin_inset CommandInset citation
LatexCommand cite
key "6327793"

\end_inset

.
 However, the main reason to prefer to use the ANN feedforward higher than
 recurrent neural networks is that the last generates greater complexity
 in the neural network training process.
 Massive iterative computation results in a slow convergence rate, as well
 as the backpropagation algorithm based on gradient descent can be trapped
 into a local optimum
\begin_inset CommandInset citation
LatexCommand cite
key "SUN201717"

\end_inset

.
 All it is added to the complexity that uncertainty analysis and stochastic
 simulation requires.
 
\end_layout

\begin_layout Standard
This motivated the development of a stochastic process model using Recurrent
 Artificial Neural Networks in order to take advantage of its aforementioned
 characteristics.
 this was possible using an approach called Reservoir Computing(
\series bold
RC
\series default
)
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

.
 Reservoir Computing is a training approach attractive as simple and fast
 compared to other approaches used in traditional recurrent ANN, all in
 order to reduce complexity, and leverage its proven ability to represents
 the characteristics of time series.
 Our model also is composed for the nondeterministic component that represents
 the white noise with a normal distribution, in order to take into account
 the uncertainty that normally affects natural processes 
\begin_inset CommandInset citation
LatexCommand cite
key "Awchi"

\end_inset

.
 Therefore, our model could be considered a new proposal in the literature.
 Finally, as a case study, it was chosen for apply this model in the well-known
 Model Parameter Estimation Experiment(
\series bold
MOPEX
\series default
) data set
\begin_inset CommandInset citation
LatexCommand cite
key "Duan20063"

\end_inset

.
 
\end_layout

\begin_layout Section
History
\end_layout

\begin_layout Standard
Initial auto-regressive models, as well as models based on Box & Jenkis
 
\begin_inset CommandInset citation
LatexCommand cite
key "BOXANDJenKys"

\end_inset

 methodology were used in forecasting problems, for example in 
\begin_inset CommandInset citation
LatexCommand cite
key "Peng2010"

\end_inset

, the author shows that there is no evidence that multivariate AR(1) models
 are inadequate as predictors.
 Studies such as 
\begin_inset CommandInset citation
LatexCommand cite
key "JAWR:JAWR70A"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Thomas"

\end_inset

 describe mathematical models, which can reproduce special characteristics
 such periodicity, considering the effects of linear correlation.
 All these studies propose, the natural behavior of times series can be
 simulated by simple linear relationship with previous data.
 
\end_layout

\begin_layout Standard
The problem with previous models is that forecasting is naturally a dynamic
 task.
 For this reason, artificial intelligence methods have been appearing as
 alternatives, with good performance as predictors of time series.
 Works such as 
\begin_inset CommandInset citation
LatexCommand cite
key "WRCR:WRCR9735"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "WRCR:WRCR11667"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lcdcampos"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "hess-20-1405-2016"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "4371334"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Awchi"

\end_inset

, they used Artificial Neural Networks (ANN) as forecasting models.
 Recently, hybrid deep neural networks such as DNN 
\begin_inset CommandInset citation
LatexCommand cite
key "deng"

\end_inset

 and its variations 
\begin_inset CommandInset citation
LatexCommand cite
key "SHEN2015243,KUREMOTO201447"

\end_inset

 also show great potential for time series prediction.
 Although these proposals have shown favorable prediction performance, global
 weight "fine-tuning" in the logistic regression layer using the backpropagation
 algorithm, limits their further development in time series prediction.
\end_layout

\begin_layout Standard
Recurrent Neural Networks have show better forecasting ability than feedforward
 ones, due to their structure
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

.
 This structure allows more parsimonious modeling of the dynamical time
 series properties.
 However, it was also demonstrated that, the recurrence structure could
 cause increased training complexity, and subsequently cause problems of
 convergence
\begin_inset CommandInset citation
LatexCommand cite
key "1"

\end_inset

.
 At the beginning of the 21st century, the concept of Reservoir Computing
 (RC) was introduced.
 
\end_layout

\begin_layout Standard
Reservoir Computing is a training approach that can be remarkably simpler
 and faster than those traditional applied in Recurrent ANN.
 Studies using RC in time series prediction were developed by 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "en81012228"

\end_inset

, the most popular reservoir computing model denominated 
\series bold
Echo State Networks (ESN)
\series default
 was used with a Bayesian regularization for forecast short-term energy
 production of small hydroelectric plants, the results indicate that the
 proposed model surpasses both, recurrent ANN feedforward and ESN in its
 simple version.
\end_layout

\begin_layout Standard
Studies such as 
\begin_inset CommandInset citation
LatexCommand cite
key "Coulibaly201076"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Abrahart201276"

\end_inset

 used ESN to forecast monthly water levels for the four Great Lakes of North
 America, the authors obtained good performance of ESN networks and attributed
 it to their highly non-linear and dynamic structure.
 Echo state networks were found to be valid alternatives to traditional
 recurrent ANN, in forecasted water inflow, for example in 
\begin_inset CommandInset citation
LatexCommand cite
key "4371334"

\end_inset

 the authors compare the performance of ESN with SONARX 
\begin_inset CommandInset citation
LatexCommand cite
key "4371335"

\end_inset

 networks, RBF networks and the ANFIS model 
\begin_inset CommandInset citation
LatexCommand cite
key "256541"

\end_inset

.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

, forecasting ability from ESN model was evaluated in a huge variety of
 large-scale basins.
 The experiments are carried out by comparing three different ESN variations
 with two RNN feedforward models.
 In addition, several aspects of ESN design are investigated in order to
 optimize hydrologically relevant information.
 Only 
\begin_inset CommandInset citation
LatexCommand cite
key "en81012228"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "SUN201717"

\end_inset

, present a hybrid system as our model proposal, in order to take advantage
 that a hybrid system can provide us in forecasting task.
 
\end_layout

\begin_layout Standard
Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Recurrent-Neural-Networks"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Training-Algorithms"

\end_inset

 briefly reviews feedforward and traditional recurrent ANN models and their
 training methods, after which a short introduction to RC is given and ESN
 is described more detailed.
 Section Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Hidrometereological-data-generat"

\end_inset

 presents details about our proposal.
 The results of some experiments are presented and discussed in Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Results-and-Discussion"

\end_inset

.
 Finally, conclusions are drawn in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusions"

\end_inset

.
\end_layout

\begin_layout Section
Theoretical Background 
\end_layout

\begin_layout Standard
In this section, we briefly summarize the theoretical background of the
 considered models, namely RNN and ESN, which are the basis of the following
 SSNESN understanding.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
The objective of this work is to automatically determine the cancer stage
 of lesions present in medical images, using semantic web and reasoning
 technologies, to process semantic annotations made by experts and provide
 clinicians with a second opinion on the classification of their patients.
 These semantic annotations are made using tools that use the AIM format
 (used by the ePAD tool) to describe and save image findings.
 Automatic cancer staging can increase the efficiency of radiologists and
 oncologists and improve the quality and uniformity of image interpretation
 by experts.
 It is important to mention that our work focuses on staging liver cancer
 due to data availability.
\end_layout

\begin_layout Plain Layout
This paper is organized as follows.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Related-work"

\end_inset

 presents related approaches.
 Section 4 describes our methodology composed of three main components:
 the ontological representation of the AIM 4.0 model, the conditions to implement
 the TNM classifier (General Ontology) and the formal representation of
 cancer staging.
 Section 5 analyses experimental data to assess our TNM classifier relevance.
 Conclusions are found in Section 6.
\end_layout

\begin_layout Section
Related work
\begin_inset CommandInset label
LatexCommand label
name "sec:Related-work"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Section
Method description
\end_layout

\begin_layout Plain Layout
In this section, we describe our methodology.
 It is comprised by three main tasks:
\end_layout

\begin_layout Enumerate
Ontological representation of the AIM 4.0 model.
 
\end_layout

\begin_layout Enumerate
\begin_inset Note Note
status open

\begin_layout Plain Layout
Generate conditions to implement the TNM classifier(General Ontology)
\end_layout

\end_inset

Creating conditions to implement reasoning based on TNM rules, using OWL
 instances.
\end_layout

\begin_layout Enumerate
Formal Representation of Cancer Staging.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/exemploIIIA.pdf
	lyxscale 75
	scale 37

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:A)TNMexamplefigure"

\end_inset

A) Axial, contrasted CT image shows multiple HCC tumors (green lines), identifie
d and annotated using the ePAD tool, There was no regional lymph node involvemen
t or metastasis.
 B) The diagram shows multiple HCCs with at least one was > 5 cm.
 This patient was classified as having TNM stageIIIA (T3a,N0,M0).
 Adapted from 
\begin_inset CommandInset citation
LatexCommand cite
key "Faria2014"

\end_inset

.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Asserting Conditions using OWL 
\end_layout

\begin_layout Description

\series bold
Condition 1 : 
\series default
Staging should consider the existence of solitary or multiple tumors on
 the same site.
\end_layout

\begin_layout Plain Layout
The AIM4-O ontology does not give us the explicit mechanics such as classes,
 subclasses, or properties, that allows us to infer whether a patient has
 a single or multiple tumors.
 In the case of multiple tumors, we constructed the following rule 
\family typewriter
\series bold
\emph on
MoreThanOneTumor
\family default
\series default
\emph default
 (in SWRL notation):
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{gather*}
\hline ImageStudy(?X)\land isImageStudyOf(?x,?y)\land isImageStudyOf(?x,?z)\land\\
DifferentFrom(?y,?z)\rightarrow MoreThanOneTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout
This rule classifies an 
\family typewriter
\series bold
\emph on
ImageStudy
\family default
\series default
\emph default
 as a member of the 
\family typewriter
\series bold
\emph on
MorethanOneTumor
\family default
\series default
\emph default
 class if an image study "X" is referenced by more than one image annotation.
 In order to classify something as 
\family typewriter
\series bold
\emph on
MorethanOneTumor
\family default
\series default
\emph default
, we created a new concept called 
\family typewriter
\series bold
\emph on
isImageStudyOf
\family default
\series default
\emph default
.
 This concept is the inverse of the 
\family typewriter
\series bold
\emph on
hasImageStudy
\family default
\series default
\emph default
 object property.
 The 
\family typewriter
\series bold
\emph on
hasImageStudy
\family default
\series default
\emph default
 property relates an 
\family typewriter
\series bold
\emph on
ImageAnnotation
\family default
\series default
\emph default
 entity to an 
\family typewriter
\series bold
\emph on
ImageStudy 
\family default
\series default
\emph default
entity.
\end_layout

\begin_layout Plain Layout
In the scenario of classifying patients with one solitary tumor, we did
 not find axioms or rules that satisfied this requirement, due to the fact
 that OWL works under the Open World Assumption.
 Open world means that just because something is not said it does not mean
 that it is not true.
 For example, I can say that the patient annotation describes a cancer lesion,
 using the 
\family typewriter
\series bold
\emph on
ImagingObservation
\family default
\series default
\emph default
 entity of the AIM4-O ontology model, but unless I explicitly say that there
 are no other lesions, it is assumed that there may be other lesion that
 I just have not mentioned or described.
\end_layout

\begin_layout Plain Layout
We have tried to solve this problem (the open world assumption) by considering
 some alternatives such as modeling again our AIM4-O ontology (e.g., setting
 the 
\family typewriter
\series bold
\emph on
hasImagingObservation
\family default
\series default
\emph default
 object property as a primitive class).
 But, this did not seem intuitive to us.
 Instead, we decided to state the number of lesions explicitly by creating
 one new concept named 
\family typewriter
\series bold
\emph on
singleLesion
\family default
\series default
\emph default
, as a data property of an 
\family typewriter
\series bold
\emph on
ImageStudy
\family default
\series default
\emph default
 entity.
 This concept denotes if an 
\family typewriter
\series bold
\emph on
ImageStudy
\family default
\series default
\emph default
 describes exactly one solitary tumor.
 We assumed that an 
\family typewriter
\series bold
\emph on
ImageStudy
\family default
\series default
\emph default
 entity describes only one tumor (
\family typewriter
\series bold
\emph on
“singleLesion {true}”
\family default
\series default
\emph default
) if only if it is referenced by only one I
\family typewriter
\series bold
\emph on
mageAnnotation
\family default
\series default
\emph default
 entity.
 However, it was not possible to formulate this using only OWL.
 Instead, this information was provided by a data structure that was generated
 as part of the process of parsing the AIM-XML image annotations to create
 AIM4-O individuals.
 Finally, to classify annotations that describe a single lesion, we constructed
 the rule 
\family typewriter
\series bold
\emph on
SingleTumor
\family default
\series default
\emph default
 (in SWRL notation):
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{gather*}
\hline ImageStudy(?X)\land singleLesion(?X,?val)\land\\
equal(?val,true)\rightarrow singleTumor(?X)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Description
Condition 2: Staging should consider if tumors are either bigger or minor
 than a certain size in cm.
\end_layout

\begin_layout Plain Layout
This condition was easily implemented by getting the value from the data
 property
\family typewriter
\series bold
\emph on
 values
\family default
\series default
\emph default
 on the 
\family typewriter
\series bold
\emph on
CalculationResult
\family default
\series default
\emph default
 entity.
 This entity is related to the 
\family typewriter
\series bold
\emph on
ImageAnnotation
\family default
\series default
\emph default
 entity through the 
\family typewriter
\series bold
\emph on
hasCalculationEntity
\family default
\series default
\emph default
 object property.
 In order to satisfy this condition, we assert the following rules taking
 5 centimeters as the longest dimension of the target liver lesion (in SWRL
 notation): 
\end_layout

\begin_layout Plain Layout
\noindent
\align center

\series bold
LessThan5cmTumor:
\series default
 
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\land\\
hasCalculationResult(?y,?z)\land\\
values(?z,?val)\land lessThan(?val,5)\rightarrow lessThan5cmTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center

\series bold
MoreThan5cmTumor:
\series default
 
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\land\\
hasCalculationResult(?y,?z)\land\\
values(?z,?val)\land greaterThan(?val,5)\rightarrow MoreThan5cmTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Description
Condition 3: Staging should consider lesions in adjacent organs.
\end_layout

\begin_layout Plain Layout
To satisfy this condition, the most complicated criterion of classification,
 we had to consider the fact that a cancerous tumor can spread through out
 the body.
 For that, we needed to create one new concept, based on the 
\family typewriter
\series bold
\emph on
Lesion
\family default
\series default
\emph default
 class from the Onlira ontology 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokciyan2014"

\end_inset

.
 The 
\family typewriter
\series bold
\emph on
Lesion
\family default
\series default
\emph default
 class handles important characteristics of a lesion, such as composition,
 density, size, shape, etc.
 But, unfortunately, they are not enough for TNM classification and reasoning.
 For this reason, we added 3 properties to it and created the subclass
\family typewriter
\series bold
\emph on
 OutsideLesion
\family default
\series default
\emph default
, these properties are:
\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/hasLocationOP.pdf
	lyxscale 50
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:properties"

\end_inset

 General Ontology adds to the 
\series bold
Onlira:Lesion
\series default
 class 2 properties defined as necessary for the TNM representation.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\family typewriter
\series bold
\emph on
hasLocation
\family default
\series default
\emph default
 (object property): This property indicates the lesions location based on
 Radlex taxonomy.
 This property relates Onlira 
\family typewriter
\series bold
\emph on
Lesion
\family default
\series default
\emph default
 class instances to Radlex 
\family typewriter
\series bold
\emph on
AnatomicalEntity
\family default
\series default
\emph default
 class instances (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:properties"

\end_inset

).
 
\end_layout

\begin_layout Itemize

\family typewriter
\series bold
\emph on
isRegionalLymphNodeAffected
\family default
\series default
\emph default
 (data property): This property denotes whether a lesion is found in some
 lymph node.
 It was useful to enable classification criteria such as N0 and N1 (see
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:properties"

\end_inset

).
\end_layout

\begin_layout Itemize

\family typewriter
\series bold
\emph on
isAdjacentOrgan
\family default
\series default
\emph default
 (data property): This property denotes whether a lesion with a 
\family typewriter
\series bold
\emph on
hasLocation
\family default
\series default
\emph default
 value 
\family typewriter
\emph on
"X"
\family default
\emph default
 is close to any adjacent orga
\family typewriter
n
\family default
.
 In accordance with the TNM liver classification criterion, which is the
 case of study in this work, we considered as adjacent organs to the liver
 
\begin_inset CommandInset citation
LatexCommand cite
key "Faria2014"

\end_inset

; the pancreas, duodenum and colon (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:radlexclass"

\end_inset

).
 Furthermore, we grouped these concepts as organs in radlex representation,
 creating two new classes, 
\family typewriter
\series bold
\emph on
AdjacentOrganGroup
\family default
\series default
\emph default
 and 
\family typewriter
\series bold
\emph on
NoAdjacentOrganGroup
\family default
\series default
\emph default
:
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Formula 
\begin{gather*}
\hline NoAdjacentOrganGroup\subseteq RadlexEntity.Organ\\
AdjacentOrganGroup\subseteq RadlexEntity.Organ\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
\series bold
\emph on
AdjacentOrganGroup
\family default
\series default
\emph default
 and 
\family typewriter
\series bold
\emph on
NoAdjacentOrganGroup 
\family default
\series default
\emph default
classes indicate whether a body organ is considered adjacent or not to the
 organ where the primary tumor was located.
 The primary organ defines the type of staging system to use, in our case,
 this organ was the liver.
 Finally, we constructed the following rule (in SWRL notation) to indicates
 whether an 
\family typewriter
\series bold
\emph on
OutsideLesion 
\family default
\series default
\emph default
is located in an adjacent organ:
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Formula 
\begin{gather*}
\hline Lesion(?x)\land adjacentOrganGroup(?y)\land\\
hasLocation(?x,?y)\rightarrow isAdjacentOrgan(?x,true)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout
Once the above requirements were adequately covered using OWL and SWRL rules,
 we constructed the axioms and rules in order to be able to automatically
 classify cancer lesions, based on the TNM system.
 We noticed that the way we modeled things mattered.
 For example, it was easier to define 
\family typewriter
\emph on
N1a
\family default
\emph default
 and 
\family typewriter
\emph on
N0
\family default
\emph default
 criteria and reuse their definitions for 
\family typewriter
\emph on
M0
\family default
\emph default
, rather than to start with the definition of 
\family typewriter
\emph on
M0
\family default
\emph default
 and end up handling complex closures.
 With the use of the AIM4-O ontology, anatomical concepts can easily be
 related to each other as demonstrated previously.
 
\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/drawingRadlextaxonomyLiver.pdf
	lyxscale 50
	scale 18

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:radlexclass"

\end_inset

Getting the subclass-hierarchy from Radlex.
 
\family typewriter
\series bold
\emph on
AdjacentOrganGroup (Pancreas, Spleen, Stomach, Gallblader,and Colon)
\family default
\series default
\emph default
 and 
\family typewriter
\series bold
\emph on
NoAdjacentOrganGroup (Lymph nodes, Lung) 
\family default
\series default
\emph default
classes are created regarding the organ where the primary tumor was located
 (in this case, the liver).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Experimental Study and Results
\end_layout

\begin_layout Plain Layout
In this section, we first describe our experimental datasets, based on actual
 medical images and reports.
 Then, we evaluate the expressivity of the AIM4-O ontology.
 Finally, we present a quantitative evaluation of our TNM classifier for
 semantic image findings, which is the objective of this work, using precision
 and recall.
\end_layout

\begin_layout Subsection
Datasets
\end_layout

\begin_layout Plain Layout
Our first dataset is a set of real clinical reports of Hepatocellular Carcinoma
 (HCC) patients from The NCI’s Genomic Data Commons (GDC).
 In this work, all experiments were supported by the GDC data.
 An important requirement to enable a feasible clinical evaluation was to
 have an image dataset to validate the results of the GDC clinical reports.
 To cover this requirement, we used the TCIA database 
\begin_inset CommandInset citation
LatexCommand cite
key "Clark2013"

\end_inset

.
 It hosts a large archive of medical images about cancer, it is accessible
 for public download and it is related to GDC records by a patient 
\family typewriter
\series bold
\emph on
subject ID
\family default
\series default
\emph default
.
 The imaging modality selected was computed tomography (CT).
 The downloaded images were loaded into the ePAD annotation tool and were
 annotated.
\end_layout

\begin_layout Plain Layout
While TNM staging could be applied to other types of cancer, this work focuses
 on staging liver.
 One reason is the availability of clinical data and images.
 For a given patient, the input to our TNM classifier consists of AIM files
 (image annotations) and the output consists of the Cancer Staging for this
 patient.
\end_layout

\begin_layout Subsection
Quantitative assessment of AIM4-O ontology
\end_layout

\begin_layout Plain Layout
According to Blomqvist et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Blomqvist2012"

\end_inset

, "
\emph on
the ontological evaluation is the process of assessing an ontology with
 respect to certain criteria, using certain measures
\emph default
".
 In this work, we undertook the evaluation of the AIM4-O ontology from the
 functional point of view.
 To achieve this, we carried out a task-focused assessment and inference
 requirements 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokciyan2014"

\end_inset

.
\end_layout

\begin_layout Plain Layout
In order to evaluate the AIM4-O ontology, we studied and evaluated how it
 could help in searching clinical reports that describe image findings (reports
 about cancer).
 For this purpose, we compared two different approaches:
\end_layout

\begin_layout Itemize
Ontology-based (semantic) search: If the clinical reports are described
 as AIM4-O individuals, these reports can be searched using description
 logic query languages (DL query).
\end_layout

\begin_layout Itemize
Natural Language process-based (keyword) search: Clinical reports and image
 findings are usually written in natural language, therefore, a method for
 searching can be keyword search.
\end_layout

\begin_layout Plain Layout
In order to highlight the differences between these two approaches, we describe
 four queries expressed both in DL (DL query) and keywords (see Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:queries"

\end_inset

):
\end_layout

\begin_layout Enumerate
Q1- Find all reports related to an image observation (tumor observation).
\end_layout

\begin_layout Enumerate
Q2- Find all reports that describe multiple tumors.
\end_layout

\begin_layout Enumerate
Q3- Find all reports that contain a tumor observation that has a size greater
 than 8 cm.
\end_layout

\begin_layout Enumerate
Q4- Find all reports that contain a tumor observation with descriptors (e.g.,
 invasion, mass, vascular).
\end_layout

\begin_layout Plain Layout
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:queries"

\end_inset

Description logic and keyword representation for four queries.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="1.5cm">
<column alignment="center" valignment="top" width="7cm">
<column alignment="center" valignment="top" width="2.5cm">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Query ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL query
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Keyword query
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations some (hasImageAnnotations some (hasImagingObservation some
 (ImagingObservationEntity and label value "Lesion type "))) 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tumor 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations min 2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Multiple tumor 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations some (hasImageAnnotations some (hasCalculationEntity some
 (hasCalculationResult some (some values float [> 8.0f])))) 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tumor size greater than 8 cm 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasImagingObservationCharacteristic 1 min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vascular tumor invasion mass 
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
We have considered the following points in order to evaluate both approaches:
\end_layout

\begin_layout Itemize
The evaluation was based on GDC reports: We randomly took 15 radiology reports
 of different patients written in natural language and converted them into
 AIM4-O instances.
\end_layout

\begin_layout Itemize
A report was retrieved if it satisfied the DL query or it collects all keywords
 in the search query.
\end_layout

\begin_layout Itemize
Finally, we compared the precision and recall against a gold standard.
 The gold standard was determined by a radiologist manually.
\end_layout

\begin_layout Plain Layout
The four queries with corresponding precision and recall results are showing
 in Table
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:prexrecallontology"

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:prexrecallontology"

\end_inset

Recall and Precision values for the four queries.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="1.2cm">
<column alignment="left" valignment="top" width="1.8cm">
<column alignment="left" valignment="top" width="2.3cm">
<column alignment="left" valignment="top" width="1.8cm">
<column alignment="left" valignment="top" width="2.3cm">
<row>
<cell multicolumn="1" alignment="left" valignment="top" topline="true" rightline="true" usebox="none" width="1.8cm">
\begin_inset Text

\begin_layout Plain Layout
Query ID
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Semantic search- DL
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none" width="3.5cm">
\begin_inset Text

\begin_layout Plain Layout
Keyword search
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Precision
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Recall
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Presicion
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Recall
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q2
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.67
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.7
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description
Observations 
\end_layout

\begin_layout Plain Layout
By analyzing the four queries we can see that the semantic search has the
 greatest number of relevant documents retrieved:
\end_layout

\begin_layout Description
Q1: With the semantic approach, 15 reports were retrieved with a precision
 and recall of 1 (15/15).
 With the keyword search, 12 reports were retrieved with a precision of
 1 (12/12) and recall of 0.8 (12/15).
 
\end_layout

\begin_layout Description
Q2: With the semantic approach, 5 reports were retrieved with a precision
 and recall of 1 (5/5).
 With the keyword search, 5 reports were retrieved with a precision and
 recall of 0.4 (2/5).
 
\end_layout

\begin_layout Description
Q3: With the semantic search, 10 reports were retrieved with a precision
 of 0.9 (9/10) and recall of 0.9 (9/10).
 With the keyword search approach no reports were retrieved, because there
 were not any reports that contained all the query words (i.e., lesion size
 greater than 8 cm).
 
\end_layout

\begin_layout Description
Q4: With the semantic search, 15 reports were retrieved with a precision
 of 0.67 (10/15) and recall of 1 (10/10).
 With the keyword search, 7 reports were retrieved with a precision of 1
 (7/7) and recall of 0.7 (7/10).
 
\end_layout

\begin_layout Plain Layout
The semantic search approach performance was better, with recall values
 close to 1 and always better than the keyword search.
 Also, in all but one case, precision values were better for the semantic
 search.
 The keyword search had 0 precision and recall for the query 3, which is
 a very bad result.
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Classification using the Recist Criteria
\end_layout

\begin_layout Plain Layout
The RECIST (Response Evaluation Criteria In Solid Tumors) guideline allows
 a standardized assessment of tumor burden and tumor response during therapy.
 Here, a sum of the diameters for all target lesions is calculated and reported
 as the baseline for follow-up and indicates therapy response/failure
\begin_inset CommandInset citation
LatexCommand cite
key "Recist"

\end_inset

.
 
\end_layout

\begin_layout Plain Layout
A considerable part of guidelines on Recist criteria can be automated using
 the AIM4-O ontology model and image annotations.
 However, this is not done by defining logical axioms and SWRL rules in
 OWL, as we do with other types classification such as TNM.
 That happens because Recist is based on value comparisons and OWL uses
 an open world assumption.
 Instead, we use SPARQL to retrieve relevant data to classify findings by
 comparing their measurement values to size specifications provided by Recist.
 
\end_layout

\end_inset


\end_layout

\begin_layout Description
\begin_inset Note Note
status collapsed

\begin_layout Description
Recist specifications:
\end_layout

\begin_layout Plain Layout
Baseline documentation of “Target” and “Non-Target” lesions
\end_layout

\begin_layout Itemize
All measurable lesions, up to a maximum of 2 lesions per organ and 5 lesions
 in total, representative of all involved organs should be identified as
 target lesions, recorded and measured at baseline.
 
\end_layout

\begin_layout Itemize
A sum of the Longest Diameter (LD), for all target lesions, will be calculated
 and reported as the baseline sum LD.
 The baseline sum LD will be used as reference by which to characterize
 the objective tumor response.
 
\end_layout

\begin_layout Itemize
All other lesions (or sites of disease) should be identified as non-target
 lesions and should also be recorded at baseline.
 Measurements of these lesions are not required, but the presence or absence
 of each should be noted throughout follow-up.
\end_layout

\begin_layout Description
Response Criteria evaluation of target lesions
\end_layout

\begin_layout Itemize
Complete Response (CR): Disappearance of all target lesions 
\end_layout

\begin_layout Itemize
Partial Response (PR): At least a 30% decrease in the LD sum of the target
 lesions, taking as reference the baseline LD sum.
 
\end_layout

\begin_layout Itemize
Stable Disease (SD): Neither sufficient shrinkage to qualify for PR nor
 sufficient increase to qualify for PD, taking as reference the smallest
 LD sum since the treatment started.
 
\end_layout

\begin_layout Itemize
Progressive Disease (PD): At least a 20% increase in the LD sum of the target
 lesions, taking as reference the smallest LD sum recorded since the treatment
 started or the appearance of one or more new lesions 
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
Asserting Recist guidelines using OWL and SPARQL
\end_layout

\begin_layout Plain Layout
The guidelines of Recist in detail in 
\begin_inset CommandInset citation
LatexCommand cite
key "Recist"

\end_inset

, represent rules and most of them were implemented using SPARQL (rules
 related to non-target lesions were not implemented):
\end_layout

\begin_layout Plain Layout

\series bold
Selection of target lesions
\series default
:The selection of final target lesions, from the set of potential lesions,
 is performed by the radiologist.
 However, this selection can also be implement using the following rule
 (in SWRL notation):
\end_layout

\begin_layout Plain Layout
\begin_inset space \space{}
\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\series bold
Srwl rule that classifies potential target lesions based on tumor size (<15mm):
\end_layout

\begin_layout Plain Layout
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\\
\land hasCalculationResult(?y,?z)\\
values(?z,?val)\land greaterThan(?val,1.5)\rightarrow isAdjacentOrgan(?x,true)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Verification of target lesions:
\series default
 It is verified that there are at most five target lesions selected and
 that each organ appears at most twice as the lesion location.
 This is done by the following SPARQL ASK queries: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that verifies that there are at most five target lesions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#>     	
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>     
\end_layout

\begin_layout Plain Layout

PREFIX onto: <http://www.owl-ontologies.com/Ontology1311106921.owl#>     	
\end_layout

\begin_layout Plain Layout

ASK where { Select (count(?lesion) as ?log) where {     		
\end_layout

\begin_layout Plain Layout

		?anotation onto:hasPerson onto:Xindividual.
     		
\end_layout

\begin_layout Plain Layout

		?anotation onto:hasImageAnnotations ?imageanotation.
     		
\end_layout

\begin_layout Plain Layout

		?imageanotation onto:hasImagingObservation ?observation.
     		
\end_layout

\begin_layout Plain Layout

		?observation onto:typeCode ?typeCode.
     		
\end_layout

\begin_layout Plain Layout

		FILTER regex(str(?typeCode),'Lesion Baseline Evaluation')     		
\end_layout

\begin_layout Plain Layout

		?imageanotation onto:hasLesion ?lesion.
     		
\end_layout

\begin_layout Plain Layout

		} 
\end_layout

\begin_layout Plain Layout

	having (?log <= 5 ) 
\end_layout

\begin_layout Plain Layout

}; 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that verifies that there are at most five target lesions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> 
\end_layout

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#> 
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>       	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>       
\end_layout

\begin_layout Plain Layout

PREFIX onto:<http://www.owl-ontologies.com/Ontology1311106921.owl#> 
\end_layout

\begin_layout Plain Layout

ASK where {  
\end_layout

\begin_layout Plain Layout

	SELECT (count(?location) as ?log) where {         		
\end_layout

\begin_layout Plain Layout

      ?anotation onto:hasPerson onto:Xindividual.
         		
\end_layout

\begin_layout Plain Layout

      ?anotation onto:hasImageAnnotations ?imageanotation.
          		
\end_layout

\begin_layout Plain Layout

      ?imageanotation onto:hasImagingObservation ?observation.
          	
\end_layout

\begin_layout Plain Layout

	  ?observation onto:typeCode ?typeCode.
          	
\end_layout

\begin_layout Plain Layout

	  FILTER regex(str(?typeCode),'Lesion Baseline Evaluation').
         	
\end_layout

\begin_layout Plain Layout

	  ?imageanotation onto:hasLesion ?lesion.
         	
\end_layout

\begin_layout Plain Layout

	  ?lesion onto:hasLocation ?location.
         		
\end_layout

\begin_layout Plain Layout

      ?location rdf:type onto:Xorgan.
         
\end_layout

\begin_layout Plain Layout

	} 
\end_layout

\begin_layout Plain Layout

having (?log <= 2) 
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Calculation of RECIST sum:
\series default
 This operation is easily implemented by getting the values from the value
 property on the CalculationResult entity.
 This entity is related to the ImageAnnotation entity through the hasCalculation
Entity object property (AIM4-O ontology), as shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AIM4example"

\end_inset

.
 The shortest axis (lymph nodes) and longest axis (other lesions) are summed
 for all target lesions by the follow SPARQL queries: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that sums shorest and longest axis of all target lesion.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\end_inset

The “
\series bold
Xdatatime
\series default
” variable can be “Lesion Baseline Evaluation” or “Follow Up”
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>     
\end_layout

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#>     	
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX onto:<http://www.owl-ontologies.com/Ontology1311106921.owl#>     	
\end_layout

\begin_layout Plain Layout

SELECT ( SUM(?values) as ?sum) where {     	
\end_layout

\begin_layout Plain Layout

	?anotation onto:hasPerson onto:Xindividual.
     	
\end_layout

\begin_layout Plain Layout

	?anotation onto:hasImageAnnotations ?imageanotation.
      
\end_layout

\begin_layout Plain Layout

	?imageanotation onto:hasImagingObservation ?observation.
      
\end_layout

\begin_layout Plain Layout

	?observation onto:typeCode ?typeCode.
      	
\end_layout

\begin_layout Plain Layout

	FILTER regex(str(?typeCode),'Xdatatime').
     
\end_layout

\begin_layout Plain Layout

	?imageanotation onto:hasCalculationEntity ?calculation.
     	
\end_layout

\begin_layout Plain Layout

	?calculation onto:hasCalculationResult ?calcresult.
     	
\end_layout

\begin_layout Plain Layout

	?calcresult onto:values ?values.
     
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Classification of response:
\series default
 Finally, the classification of complete response(CP), partial response
 (PR) or stable disease (SD) is carried out in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ShowsRecist"

\end_inset

: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/recistResult.jpg
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:ShowsRecist"

\end_inset

Shows the response classification PD (Progressive Disease: at least a 20%
 increase in the LD sum of target lesions) of a patient with one lesion
 in the liver “liver2” , with studies on dates october 31 and september
 26.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang brazilian
The reasoning, based on the four guidelines above, provide an automated
 estimate of the tumor burden, according to the RECIST criteria, on imaging
 studies at baseline and follow-up.
 This information will enable oncologists to calculate and classify patients
 response.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Automatic TNM clinical stage
\end_layout

\begin_layout Plain Layout
In this section, we calculated the classification rate of the TNM classifier.
 At first, we created an ePAD template named "TNM template" in order to
 provide to the radiologist with a pre-specified set of semantic terms for
 image annotations.
 These image annotations, which are compatible with the ePAD tool, were
 stored in the AIM-XML format.
 An example of an annotated image is presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:TNMtemplate"

\end_inset

.
\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/templateTNM.pdf
	lyxscale 50
	scale 27

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:TNMtemplate"

\end_inset

A CT image of the liver annotated using the TNM template (on the right of
 the image).
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
After, the generated image annotations (in AIM-XML format) were classified
 automatically using the TNM criteria.
 This process was duly evaluated and correctly accepted by an experienced
 radiologist, he analyzed the accuracy of the generated annotations in terms
 of semantic.
 The process we followed was:
\end_layout

\begin_layout Itemize
The data set used came from the following open databases:
\end_layout

\begin_deeper
\begin_layout Itemize
The NCI's Genomic Data Commons (GDC)
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdc.cancer.gov/
\end_layout

\end_inset

.
\end_layout

\begin_layout Itemize
The Cancer Imaging Archive (TCIA)
\begin_inset Foot
status open

\begin_layout Plain Layout
https://public.cancerimagingarchive.net/ncia/login.jsf
\end_layout

\end_inset

 (collects only images, the number of series and studies): As we working
 with TNM classification from the liver, we searched for "LIHC - Liver hepatocel
lular carcinoma" obtaining 52 patients with information available in both
 databases (images and reports).
 However, the information about tumor size was obtained by manual review
 of the medical reports.
 These reports are also available in The NCI's Genomic Data Commons.
\end_layout

\end_deeper
\begin_layout Itemize
After reading the medical reports, the radiologist was provided with an
 excel spreadsheet that provided information about medical findings, such
 as lesion size, vascular invasion, and others.
\end_layout

\begin_layout Itemize
Based on this excel file and the GDC data, we created the AIM-XML annotations
 and integrated them into our knowledge base (as AIM4-O ontology individuals).
\end_layout

\begin_layout Itemize
The AIM files were used as inputs for our TNM classifier.
 The produced output was compared with the TNM values that physicians reported.
\end_layout

\begin_layout Plain Layout
In this paper, the 7th edition of TNM 
\begin_inset CommandInset citation
LatexCommand cite
key "Faria2014"

\end_inset

 has been employed.
 The AIM image annotations were generated based on 52 different clinical
 reports.
 Our automatic staging approach was evaluated by using precision and recall
 values.
 The cancer stages generated by our TNM classifier were compared to those
 described by the physicians who created the original clinical reports (our
 gold standard).
 One patient, with a subject ID "TCGA-DD-A1EJ", was removed from this analysis.
 The specialist considered that the TNM classification reported by the physician
 in his respective clinical report was incorrect (more information below).
\end_layout

\begin_layout Plain Layout
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Results"

\end_inset

Confusion Matrix of cancer stages predicted by the TNM classifier versus
 the values of the doctors placed in the reports.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n = 51
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Actual Stages
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
I
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
II
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IIIA
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IIIB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IVA
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Predicted Stages
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
I
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
24
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
II
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IIIA
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IIIB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IVA
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
For the calculation of precision and recall, the result is considered positive
 when the automatic staging coincides with the stage given by physicians
 who created the original clinical report.
 See Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Results"

\end_inset

.
\end_layout

\begin_layout Plain Layout
Precision was 85.7% and recall 81.0% (for 51 patients).
 This means that, for precision, at 85.7% of the time the system agreed with
 the staging given by physicians.
 For the recall, this means that, of all the times that a given stage was
 reported by a physician, in 81.0% of cases the system agreed with him/her.
 It is important to note that, even when the system diverged from physicians,
 the maximum difference between them was only one stage.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
We discussed these patient staging results with a physician (DR) from the
 Radiology Department of Stanford University School of Medicine, who found
 this results very good.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:matrixconfusion"

\end_inset

 we show the results of the evaluation summarized in the color scale matrix.
 It represents our confusion matrix for a multi-stage classification.
 The darker the square in the diagonal of the matrix means that the respective
 class was better classified.
 The other squares in grays, outside of the diagonal, indicates that the
 class in the vertical axis was confused by the classifier with the correspondin
g class on the vertical axis.
\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/confusionmatrix2.pdf
	lyxscale 70
	scale 38

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:matrixconfusion"

\end_inset

Confusion matrix for TNM multi-stage classification
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
For early stages of cancer, such as I, II, IIIA, the percentage of misclassifica
tions (e.g., false positives and false negatives) was very small.
 They are represented by the highlighted diagonal of the matrix (Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:matrixconfusion"

\end_inset

).
 For more advanced stages of cancer, such as IIIB or IVA, it was larger
 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:histogram"

\end_inset

).
 This may have happened simply because we had few patients at these stages
 or because these stages are described by relatively more complex concepts.
\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/classhistogram.pdf
	scale 39

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:histogram"

\end_inset

Summary of Histograms for each TNM stage from the Confusion Matrix (51 reports):
 FN - False Negatives, FP - False Positives and TP - True Positives.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
Our classifier also revealed the fact that there are clinical reports with
 inaccurate staging diagnosis.
 An example of this situation was the clinical case with subject ID "TCGA-DD-A1E
J".
 The result of the classifier was considered correct by our expert.
 The stage predicted was the Stage I, however, the stage described by the
 medical report was the Stage III
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdc-portal.nci.nih.gov/cases/52292ffc-0902-4d97-b461-20723987a177
\end_layout

\end_inset

.
 As it was the only case in which the difference between the classifier’s
 stage and the physician’s evaluation differed by more than one level, our
 expert decided to analyze the report and concluded that the classifier’s
 stage was correct.
 He recommended us to not use this patient’s data, so this report was excluded
 from the analysis.
 Examples, like this, serve to warrant the importance of improving clinical
 decision support systems (through the use of image metadata in cancer treatment
).
\end_layout

\end_inset


\end_layout

\begin_layout Section
Recurrent Neural Networks 
\begin_inset CommandInset label
LatexCommand label
name "sec:Recurrent-Neural-Networks"

\end_inset


\end_layout

\begin_layout Standard
Recurrent Neural Networks (RNN) are a subclass of ANN characterized by cyclic
 graphs in its structure.
 These cycles accumulate previous activities and allow the network stores
 internal states.
 These internal states avoid needing to feed the network with the history
 of previous input and output as the Time-Delay Neural Network
\begin_inset CommandInset citation
LatexCommand cite
key "Kuna2015"

\end_inset

.
 And can use the input sequences in order to perform temporal tasks as forecasti
ng.
 The RNN output can be described by: 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $Output_{t+1}\cong Forecasting\left(RNNstate,Input_{t},Output_{t}\right)$
\end_inset


\end_layout

\begin_layout Standard
The figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:elmanandwilliam"

\end_inset

 shows the two types of traditional recurrent ANN models, the Elman recurrent
 network 
\begin_inset CommandInset citation
LatexCommand cite
key "Elman90findingstructure"

\end_inset

 and the Willians-Zipser fully recurrent network
\begin_inset CommandInset citation
LatexCommand cite
key "Williams:1989:LAC:1351124.1351135"

\end_inset

.
 These neural networks have cyclic connections on their structure.
 For instance, the Elman network connects its input to all neurons, including
 output ones, hidden and output neurons are fully interconnected.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/RNNewilliamandelman.pdf
	lyxscale 30
	scale 15

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:elmanandwilliam"

\end_inset

(b) Elman recurrent Artificial Neural Network.
 a) William-zipser fully recurrent Artificial Neural Network.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Learning Algorithms
\begin_inset CommandInset label
LatexCommand label
name "sec:Training-Algorithms"

\end_inset


\end_layout

\begin_layout Standard
Basically, supervised learning means to adjust the network weight matrix
 
\series bold

\begin_inset Formula $W$
\end_inset

 
\series default
using the optimization algorithms, in order to minimize the output error.
 This is probably the most common approach used among the current types
 of neural network systems where the input and output are used in the network.
 A well known training method is the Standard Backpropagation algorithm
 (BP)
\begin_inset CommandInset citation
LatexCommand cite
key "Rumelhart:1986:PDP:104279"

\end_inset

.
 Backpropagation is a method to calculate the gradient of the loss function
 with respect to the weights.
 This technique approximates the local minimum by changing these weights
 along of negative error gradient direction.
 The objective function 
\begin_inset Formula $E(W)$
\end_inset

 is calculated after BP applies an update to the weights in the network;
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle\omega_{ji}=-\eta\frac{\partial E}{\partial\omega_{ji}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\eta$
\end_inset

 is constant positive value called learning rate.
 The momentum rate 
\begin_inset Formula $\beta$
\end_inset

 can be added to the current weight change, this often speeds up the learning
 process
\begin_inset CommandInset citation
LatexCommand cite
key "Sutskever2013"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle\omega_{ji}^{'}=\beta\triangle\omega_{ji}-\eta\frac{\partial E}{\partial\omega_{ji}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Weight updates can be performed in online mode or based on the mean error
 over all training data(that is called batch mode).
 Besides, more sophisticated alternatives to the BP algorithm, such as the
 Levenberg-Marquardt(LM) have been found faster convergence algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "hess-9-111-2005"

\end_inset

.
 In this algorithm the weight update is obtained by the following equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\varDelta\omega=-\left[H+\mu I\right]^{-1}J^{T}\rho
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\mu$
\end_inset

 is a learning rate, 
\series bold

\begin_inset Formula $J$
\end_inset

 
\series default
the jacobian matrix, which is the first derivatives of the network error
 with respect to the weights and biases, and 
\begin_inset Formula $\rho$
\end_inset

 is a vector of network errors.
 Finally, 
\series bold

\begin_inset Formula $H$
\end_inset

 
\series default
is an approximation of the Hessian matrix.
\end_layout

\begin_layout Subsection
Recurrent Learning
\end_layout

\begin_layout Standard
Standard BP algorithm is not suited for networks with cycles in them.
 Nonetheless, we can apply some artifices and see the RNN like feedforward
 network by unfolding this RNN network in time as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:unfold"

\end_inset

.
 The RNN is interpreted as layered network that keeps the same weights to
 reusing, we assume the time delay of 1 in each connection in order to create
 an equivalent feedforward network
\begin_inset CommandInset citation
LatexCommand cite
key "Williams90anefficient"

\end_inset

.
 This extension of the BP method is called Backpropagation Through Time(BPTT).
 In BPTT the number of networks copies is equal to time step 
\series bold

\begin_inset Formula $T$
\end_inset


\series default
.
 It would be impractical in the online training since the memory footprint
 grows linearly with the time.
 Therefore, the network unfolding is limited to a chosen truncation depth
 to keep the method feasible 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/RNNunfoldprocess-ES.pdf
	lyxscale 30
	scale 15

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:unfold"

\end_inset

Recurrent Neural Network unfolded in time, the hidden units grouped at time
 
\begin_inset Formula $T$
\end_inset

 get inputs from other neurons at previous time steps such as 
\begin_inset Formula $T-1,T-2,\ldots T$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
More sophisticated methods were developed to overcome BPTT limitations,
 for example Real-Time Recurrent Learning
\begin_inset CommandInset citation
LatexCommand cite
key "Williams:1989:LAC:1351124.1351135"

\end_inset

, Clockwork Recurrent Network (CW-RNN) that splits hidden layer into M modules
 running at different clocks
\begin_inset CommandInset citation
LatexCommand cite
key "Kuna2015"

\end_inset

 and the extended Kalman Filter (EKF) method, which each time estimates
 optimal weights, given a series of observed outputs, for more details see
\begin_inset CommandInset citation
LatexCommand cite
key "Sum:1998:EKF:296468.296482"

\end_inset

.
 However, these methods suffer shortcomings related to the modeling complexity
 and optimization(gradient)
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

.
 That means, many updates may be necessary and it could be computationally
 expensive, the gradient information might becomes useless by weight updates
 procedure
\begin_inset CommandInset citation
LatexCommand cite
key "doya1992bifurcations"

\end_inset

.
\end_layout

\begin_layout Subsection
Echo state network
\end_layout

\begin_layout Standard
Echo state networks (ESN) establish an efficient and powerful approach to
 recurrent neural network (RNN) training.
 Unlike the traditional RNN, such as Elman networks, that are organized
 in layers and contain feedback connections.
 The core part of ESN is a single reservoir consisting of a mass of neurons
 that are randomly interconnected and self-connected.
 The reservoir itself remains unchanged, once it is selected.
 The efficient learning can be achieved by determining the weights of the
 connections between the reservoir and the output layer.
 ESN overcome the slow convergence, high computational requirements and
 suboptimal estimates of the model parameters.
 All these are founded in training algorithms based on direct optimization
 of the network weights.
 
\end_layout

\begin_layout Standard
It may seem surprising that an ANN with random connections may be effective,
 but random parameters have been successful in several domains.
 For example, random projections have been used in mechanical learning and
 dimensionality reduction 
\begin_inset CommandInset citation
LatexCommand cite
key "Datar:2004:LHS:997817.997857"

\end_inset

, and more recently, random weights have been shown to be effective for
 convolutional neuronal networks in problems with training data.
 very limited 
\begin_inset CommandInset citation
LatexCommand cite
key "Jarret,Saxe_551"

\end_inset

.
 Therefore, it should not be surprising that random connections are effective
 at least in some situations.
\end_layout

\begin_layout Standard
Although ESN does not solve the problem of training RNN entirely, its impressive
 performance suggests that an initialization based on ESN could be successful.
 This is confirmed by the results of 
\begin_inset CommandInset citation
LatexCommand citep
key "Ilya"

\end_inset

 in his work.
\end_layout

\begin_layout Standard
Now we will proceed to give the formal description of the ESN network.
\end_layout

\begin_layout Subsection
Training Echo State Networks
\end_layout

\begin_layout Standard
The RC paradigm creates a random ANN that remains unchanged throughout the
 training.
 This ANN is called 
\begin_inset Quotes eld
\end_inset

Reservoir
\begin_inset Quotes erd
\end_inset

, which is passively excited by the input signal and maintains a non-linear
 transformation of the input history in its state.
 
\end_layout

\begin_layout Standard
The main equation of ESN, where we do not use any input, but only the output
 feedback, is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x(t+1)=f(W\text{·}x(t)+W^{fb}\text{·}y(t))
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Or alternatively, with entries:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x(t+1)=f(W^{in}\text{·}u(t)+W\text{·}x(t)+W^{fb}\text{·}y(t))
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $x(t)$
\end_inset

 is the vector that contains all the states of the reservoir at time 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $W$
\end_inset

 is the reservoir matrix, where each input 
\begin_inset Formula $W_{ij}$
\end_inset

 corresponds to the connection between the neuron 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, 
\begin_inset Formula $W^{fb}$
\end_inset

 is the matrix of the feedback vector, and 
\begin_inset Formula $y(t)$
\end_inset

 is the output at time 
\begin_inset Formula $t$
\end_inset

.
 In the second version of the equation we see 
\begin_inset Formula $u(t)$
\end_inset

 multiplied by the input vector 
\begin_inset Formula $W^{in}$
\end_inset

.
 This equation represents the initial phase of the network, where the output
 actually works as input, driving the dynamics of the network.
 The function 
\begin_inset Formula $f$
\end_inset

 is generally chosen to be the hyperbolic tangent for the internal neurons
 (
\begin_inset Formula $tanh$
\end_inset

) and the identity function for the output neuron.
 To account for echo state property, the internal weight matrix 
\begin_inset Formula $W$
\end_inset

 is typically scaled as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
W\leftarrow\frac{\alpha}{\mid\lambda_{max}\mid}W
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mid\lambda_{max}\mid$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is the spectral radius of 
\begin_inset Formula $W$
\end_inset

, and 
\begin_inset Formula $\alpha\in(0,1)$
\end_inset

 is a scaling parameter.
 Additionally, due to the influence of initial reservoir states, a certain
 number of initial steps need to be abandoned during the training, called
 washout phase
\begin_inset CommandInset citation
LatexCommand cite
key "SUN201717"

\end_inset

.
\end_layout

\begin_layout Standard
The algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:training_ESN"

\end_inset

 summarizes how the training of an ESN network is carried out.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
caption{training ESN}
\end_layout

\begin_layout Plain Layout


\backslash
State {$i 
\backslash
gets historicalSequence_{size}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$j 
\backslash
gets reservoir_{size}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$M 
\backslash
gets array(i,j)$}  
\backslash
Comment{state matrix} 
\end_layout

\begin_layout Plain Layout


\backslash
State {$Forgetpoints 
\backslash
gets Z$} 
\backslash
Comment{forget initial steps} 
\end_layout

\begin_layout Plain Layout


\backslash
While{$t 
\backslash
le samples_{size}$}
\end_layout

\begin_layout Plain Layout


\backslash
If{$t 
\backslash
le Forgetpoints$}
\end_layout

\begin_layout Plain Layout


\backslash
State continue;
\end_layout

\begin_layout Plain Layout


\backslash
Else
\end_layout

\begin_layout Plain Layout


\backslash
State {$M(t,:)
\backslash
gets x(t)$}
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:training_ESN"

\end_inset

Standard training algorithm of ESN network, the states are collected in
 an 
\begin_inset Formula $M$
\end_inset

 matrix that has in each row the status vector 
\begin_inset Formula $x(t)$
\end_inset

 and in each column the neurons of the reservoir.
 Therefore, 
\begin_inset Formula $M$
\end_inset

 is a matrix of examples (rows) by the reservoir dimension (columns).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Echo State Network learning
\end_layout

\begin_layout Standard
The linear output layer of an ESN network is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y\left(n\right)=W_{out}\left[1;u\left(n\right);x\left(n\right)\right]\label{eq:readoutequation-1-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $y\left(n\right)\in R^{N_{y}}$
\end_inset

, is the output vector with dimension 
\begin_inset Formula $N_{y}$
\end_inset

 of the network, 
\begin_inset Formula $W_{out}\in R^{N_{y}\times\left(1+N_{u}+N_{x}\right)}$
\end_inset

, is the output weights matrix and 
\begin_inset Formula $\left[.;.;.\right]$
\end_inset

 means a vertical vector concatenation (or matrix).
 Now in order to get the matrix 
\begin_inset Formula $W_{out}$
\end_inset

, we can use linear algebra procedures such as Pseudo-Inverse or Ridge regressio
n 
\begin_inset CommandInset citation
LatexCommand cite
key "Jaeger2001a"

\end_inset

.
\end_layout

\begin_layout Subsection
Moore-Penrose pseudoinverse
\end_layout

\begin_layout Standard
The Pseudoinverse, or Moore-Penrose Pseudoinverse, is a generalization of
 a inverse matrix, but for matrices that are not rectangular.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
W_{out}=pinv(M)∗T\label{eq:pinv}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $W_{out}$
\end_inset

, is the vector of output weights, and 
\begin_inset Formula $T$
\end_inset

, is the vector of expected values.
 Therefore, we have a set of 
\begin_inset Formula $m$
\end_inset

 equations with 
\begin_inset Formula $n$
\end_inset

 unknowns, where 
\begin_inset Formula $n$
\end_inset

 is the number of neurons, the size and the inputs of 
\begin_inset Formula $W_{out}$
\end_inset

 are the respective weights of the states of the neurons.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $A$
\end_inset

 be  
\begin_inset Formula $(m\times n)$
\end_inset

 matrix, then the Moore-Penrose is unique, denote 
\begin_inset Formula $A*$
\end_inset

, have the size 
\begin_inset Formula $n\times m$
\end_inset

 and satisfy the following four conditions:
\end_layout

\begin_layout Enumerate
\begin_inset Formula 
\[
AA*A=A
\]

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula 
\[
A*AA*=A*
\]

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula 
\[
\left(A*A\right)^{T}=A*A
\]

\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula 
\[
\left(AA*\right)^{T}=AA*
\]

\end_inset


\end_layout

\begin_layout Subsection
Ridge Regression
\end_layout

\begin_layout Standard
Finding the optimal weights, which minimize the squared error between 
\begin_inset Formula $y\left(n\right)$
\end_inset

 and 
\begin_inset Formula $y^{target}\left(n\right)$
\end_inset

, is equivalent to solving a system of linear equations typically overdetermined.
 The system is overdetermined, because typically 
\begin_inset Formula $T\gg1+N_{u}+N_{x}$
\end_inset

 .
\end_layout

\begin_layout Standard
There are well-known standard ways of solving the equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pinv"

\end_inset

, probably the most universal and stable solution in this context is the
 Ridge regression, also known as regression with regularization from Tikhonov:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
W_{out}=Y^{target}X^{T}\left(XX^{T}+\beta I\right)^{-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $β$
\end_inset

 is a regularization coefficient, and 
\begin_inset Formula $I$
\end_inset

 is the identity matrix.
\end_layout

\begin_layout Standard
We show only two of the methods that can be used to solve the equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pinv"

\end_inset

, although the latter is not very trivial it is preferred to use.
 Next, the output values ​​of the network will be validated, using the adjusted
 matrix 
\begin_inset Formula $W_{out}$
\end_inset

.
\end_layout

\begin_layout Subsection
Echo State Network Validation
\end_layout

\begin_layout Standard
In this stage, the network is executed on the test data, where the states
 of the neurons at time 
\begin_inset Formula $t=0$
\end_inset

 in the validation phase are states of the neurons at time 
\begin_inset Formula $t=m$
\end_inset

 in the learning phase.
 The difference now is that the output is calculated by the network using
 the weights of 
\begin_inset Formula $W_{out}$
\end_inset

, so these values ​​are not previously known.
 The equations for the validation phase are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\widehat{y}(t)=f^{out}\left(x\left(t\right)*W^{out}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x\left(t+1\right)=f\left(W\cdot x\left(t\right)+W^{fb}\cdot\widehat{y}\left(t\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $\widehat{y}$
\end_inset

 is the output after the pseudoinverse calculation.
 It is common to use an identity output function, however in the equation
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:pinv"

\end_inset

, some non-linear transformation can be applied, such as 
\begin_inset Formula $tanh$
\end_inset

.
 Also when calculating weights (
\begin_inset Formula $W_{out}$
\end_inset

) we could use a non-linear technique, such as perceptron, SVM, or Ridge
 regression.
 Finally, to evaluate the ESN network, we usually calculate the Normalized
 Mean Square Error (NRMSE) which is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
NRMSE=\sqrt{\frac{\parallel\widehat{y}-y\parallel{}^{2}}{m*\sigma_{y}^{2}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $\sigma_{y}^{2}$
\end_inset

  is the variance of the desired output 
\begin_inset Formula $y,m$
\end_inset

 is the validation sequence, and, is the expected output, 
\begin_inset Formula $\widehat{y}$
\end_inset

 is the output calculated by the ESN network after the process Learning.
\end_layout

\begin_layout Section
Stochastic Streamflow model ESN
\end_layout

\begin_layout Standard
In the section, we present a new stochastic model architecture for time
 series prediction, SSMESN, and give the details of the whole architecture
 and learning algorithm.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Y_{v,t}=f\left(R_{v,t}+E_{v,t}\right)\label{eq:eq_general}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The model has the purpose of generating scenarios of hydrological synthetic
 data, in terms of monthly intervals, for this an architecture based on
 Recurrent Neural Networks (RNAR) was used as the deterministic component
 where:
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $Y_{v,t}$
\end_inset

, are the synthetic values ​​produced by the model,
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $E_{v,t}$
\end_inset

, are the values ​​produced by the RNAR,
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $R_{v,t}$
\end_inset

, is the stochastic component represented by the equations ([eq: randomCom]).
\end_layout

\begin_layout Standard
• The function 
\begin_inset Formula $f$
\end_inset

 represents the inverse of the preprocessing transformations.
\end_layout

\begin_layout Standard
So that our model can synthesize hydrological monthly time series (periodic,
 stationary), you have to adjust the parameters not only in time intervals
 of the series, but also in your period.
 For example, if the period is monthly, our model will be composed of 12
 stochastic components.
 In this case, the model is formed by a chain of its components, between
 the input value to the RNAR and the next period, as can be seen in the
 figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Esquema-del-proceso"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/eschema_model.pdf
	lyxscale 50
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Esquema-del-proceso"

\end_inset

Proposed stochastic process, the celestial and black spheres represent the
 stochastic and deterministic components, respectively, a chaining between
 the value of the time series of a period that is part of the input to the
 Recurrent Network of the next period.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Stochastic component
\end_layout

\begin_layout Standard
In terms of statistics, the variable 
\begin_inset Formula $R_{v,t}$
\end_inset

 represents a normally distributed random noise, which takes into account
 the uncertainty that usually affects hydrological processes.
 
\begin_inset Formula $R_{v,t}$
\end_inset

 is added to provide variability in 
\begin_inset Formula $Y_{v,t}$
\end_inset

 which remains even after 
\begin_inset Formula $Y_{v,t-1}$
\end_inset

 is known 
\begin_inset CommandInset citation
LatexCommand cite
key "loucks2005water"

\end_inset

.
 Each 
\begin_inset Formula $R_{v,t}$
\end_inset

 is independent of past values 
\begin_inset Formula $​​Y_{v,w}$
\end_inset

, where 
\begin_inset Formula $w\leq t-1$
\end_inset

, and 
\begin_inset Formula $R_{v,t}$
\end_inset

 is independent of 
\begin_inset Formula $R_{v,w}$
\end_inset

 for 
\begin_inset Formula $w\neq t-1$
\end_inset

 .
 This component is the same stochastic part from Thomas & Fiering model,
 
\end_layout

\begin_layout Subsection
First order stationary Markov model or Thomas Fiering model (Stationary)
\end_layout

\begin_layout Standard
The method consists of the use of twelve linear regression equations: 
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
\begin{aligned}Y_{jan}= & \overline{Y}_{jan}+b_{jan}\left(Y_{dec}-\overline{Y}_{dec}\right)+\varepsilon_{jan}\\
Y_{feb}= & \overline{Y}_{feb}+b_{feb}\left(Y_{jan}-\overline{Y}_{jan}\right)+\varepsilon_{feb}\\
...= & ...
\end{aligned}
\label{eq:thomas2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
From equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:thomas2"

\end_inset

, the regression analysis of 
\begin_inset Formula $Y_{t+1}$
\end_inset

 is given in 
\begin_inset Formula $Y_{t}$
\end_inset

 over years where 
\begin_inset Formula $t=1(january),2(february),...,12(december)$
\end_inset

, 
\begin_inset Formula $b_{j}$
\end_inset

 is the regression coefficient between month 
\begin_inset Formula $t+1$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

.
 The monthly regression line can be determined from previous values, by
 means of the general equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\widehat{Y}_{t+1}=\overline{Y}_{t+1}+b_{t}\left(Y_{t}-\overline{Y}_{t}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The variability of these points plotted from the regression line that reflect
 the variance on this line is added by the additional component 
\begin_inset Formula $R_{t}$
\end_inset

 (in red in the Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Random"

\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R_{t+1}=\epsilon\times\sigma_{t+1}\times\sqrt{\left(1-r_{t}^{2}\right)}\label{eq:randomCom}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where:
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $\sigma_{t+1}$
\end_inset

, is the standard deviation in month 
\begin_inset Formula $t+1$
\end_inset

.
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $r_{t}$
\end_inset

, is the correlation coefficient between months 
\begin_inset Formula $t+1$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 (throughout the historical record).
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $\epsilon=N(0,1)$
\end_inset

, a normally distributed random noise with zero mean and standard deviation
 one.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/thomas_fiering_random_es.pdf
	lyxscale 30
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Random"

\end_inset

Conditional distribution of 
\begin_inset Formula $Y_{t+1}$
\end_inset

 given 
\begin_inset Formula $Y_{t}=y_{t}$
\end_inset

 for two normal random variables.
 The red oval represents the stochastic component used by our model in its
 final form.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The procedure for using the stochastic component 
\begin_inset Formula $R_{t}$
\end_inset

 in our model is described in the follow pseudocode 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:ramdom_component"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
caption{Random Component $R_{t}$}
\end_layout

\begin_layout Plain Layout


\backslash
State {$
\backslash
textit{n} 
\backslash
gets 
\backslash
text{length of }
\backslash
textit{(Historical record)}$}
\end_layout

\begin_layout Plain Layout


\backslash
For{$t= 0 
\backslash
to 11 $}
\backslash
Comment{monthly, t:=0,january} 
\end_layout

\begin_layout Plain Layout


\backslash
State $v
\backslash
gets t$
\end_layout

\begin_layout Plain Layout


\backslash
State $j
\backslash
gets 1$
\end_layout

\begin_layout Plain Layout


\backslash
State $sum_{t}
\backslash
gets 0, sum_{t+1}
\backslash
gets 0$
\end_layout

\begin_layout Plain Layout


\backslash
While{$v 
\backslash
le n$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $sum_{t}
\backslash
gets sum_{t}+Y_{t,v}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $sum_{t+1}
\backslash
gets sum_{t+1}+Y_{t+1,v}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets j+1, v
\backslash
gets v+12*j$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
overline{Y}_{t}=
\backslash
frac{sum_{t}}{n}$}
\backslash
Comment{streamflow }
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
overline{Y}_{t+1}=
\backslash
frac{sum_{t+1}}{n}$}
\backslash
Comment{streamflow}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets 1, v
\backslash
gets t$
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout


\backslash
While{$v 
\backslash
le n$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp1_{t}
\backslash
gets temp1_{t} + 
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp2_{t}
\backslash
gets temp2_{t} + 
\backslash
left(Y_{t,v}-
\backslash
overline{Y}_{t}
\backslash
right)^{2}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp1_{t+1}
\backslash
gets temp1_{t+1} + 
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)$	
\end_layout

\begin_layout Plain Layout

	
\backslash
State $temp2_{t+1}
\backslash
gets temp2_{t+1} + 
\backslash
left(Y_{t+1,v}-
\backslash
overline{Y}_{t+1}
\backslash
right)^{2}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $j
\backslash
gets j+1, v
\backslash
gets v+12*j$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State{$
\backslash
sigma_{t}=
\backslash
sqrt{
\backslash
frac{
\backslash
left(temp2_{t}
\backslash
right)}{n-1}}$}
\backslash
Comment{standar deviation} 
\end_layout

\begin_layout Plain Layout


\backslash
State{$r_{t}=
\backslash
frac{
\backslash
left(temp1_{t}
\backslash
right)
\backslash
times 
\backslash
left(temp1_{t+1}
\backslash
right)}{
\backslash
sqrt{
\backslash
left(temp2_{t}
\backslash
right) 
\backslash
times 
\backslash
left(temp2_{t+1}
\backslash
right)}}$}
\backslash
Comment{correlation coefficient between $t$ and $t+1$} 
\end_layout

\begin_layout Plain Layout


\backslash
State{$
\backslash
epsilon=N(0,1)$} 
\backslash
Comment{normally distributed random noise}
\end_layout

\begin_layout Plain Layout


\backslash
State{$R_{t+1}=
\backslash
epsilon
\backslash
times
\backslash
sigma_{t+1}
\backslash
times
\backslash
sqrt{
\backslash
left(1-r_{t}^{2}
\backslash
right)}$}
\backslash
Comment{Stochastic component, The model is then a set of twelve regression
 equations}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:ramdom_component"

\end_inset

Calculate Random Component
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Finally to generate synthetic time series the procedure is repeated, generating
 a sequence of random numbers 
\begin_inset Formula $\left\{ \epsilon_{1},\epsilon_{2},...\right\} $
\end_inset

  that are replaced in the model, In this work, a recurrent topology  was
 used as a deterministic component.
\end_layout

\begin_layout Subsection
Echo State Component
\end_layout

\begin_layout Standard
This sequential information is preserved in the internal states or processing
 units (PU) of the Recurrent ANN, and allows to manage values at time 
\begin_inset Formula $t$
\end_inset

 without the need for pre-processing or time delay as can be seen in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Generación-de-escenarios"

\end_inset

.
 
\end_layout

\begin_layout Standard
In order to obtain a time series value at time 
\begin_inset Formula $t$
\end_inset

, in our model the Recurrent ANN receives as input the values at time 
\begin_inset Formula $t-1$
\end_inset

.
 The activation of the internal PU (echo states) is updated according to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x\left(t+1\right)=\vartheta\left(W^{in}y_{t+1}+\theta_{t+1}+Wx(t)\right)\label{eq:statesRNN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where:
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $x(t)$
\end_inset

, is the vector of internal states or PU.
\end_layout

\begin_layout Standard
• W, is the synaptic weights matrix with recurrent connection.
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $y_{t+1}$
\end_inset

, is the input signal, in month 
\begin_inset Formula $t+1$
\end_inset

.
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $W^{in}$
\end_inset

, is the synaptic weight matrix between the input signal and the PU.
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $\vartheta$
\end_inset

, represents the activation function of the internal states (usually a hyperboli
c tangent function).
\end_layout

\begin_layout Standard
• 
\begin_inset Formula $\theta_{t+1}$
\end_inset

, bias.
\end_layout

\begin_layout Standard
The output of the Recurrent ANN is calculated according to the equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{t+1}=\delta\left(W^{out}\left(x(t+1)+y_{t}\right)+\theta_{t}\right)\label{eq:ouputRNN}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where: 
\begin_inset Formula $W^{out}$
\end_inset

, is the weight matrix between the internal states 
\begin_inset Formula $x(t+1)$
\end_inset

 added to the input signals 
\begin_inset Formula $y_{t}$
\end_inset

 and the output neurons.
 
\begin_inset Formula $\delta$
\end_inset

 is the activation function of the output neurons, this is a standard tool
 for condensing very small or very large values within a logistic space.
\end_layout

\begin_layout Standard
As can be seen in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Esquema-del-proceso"

\end_inset

 the synthetic values 
\begin_inset Formula $Y_{t}$
\end_inset

 is given by the sum of the output of our Recurrent ANN (
\begin_inset Formula $E_{t}$
\end_inset

), and the stochastic part of the Thomas & Fiering model (
\begin_inset Formula $R_{t}$
\end_inset

), described by the equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq_general"

\end_inset

.
 In order to obtain a mathematical description, the equations are concatenated
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:statesRNN"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ouputRNN"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq_general"

\end_inset

, to obtain the following extended equation of our model:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{multline}
\begin{aligned}Y_{t+1}= & f\left(\delta\left(W^{out}\times\left(\vartheta\left[W^{in}y_{t}+\theta_{t}+Wx(t-1)\right]+y_{t}\right)+\theta_{t}\right)+R_{t}\right)\end{aligned}
\label{eq:final_form}
\end{multline}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/propose_model-as-ES.pdf
	lyxscale 20
	scale 4.7

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Generación-de-escenarios"

\end_inset

Generation of synthetic scenarios, the new SSNESN model is observed in detail
 in this work.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The sequential information generated by the new model is preserved in the
 internal states of the Recurrent ANN (
\begin_inset Formula $x(t)$
\end_inset

) that allow many steps in time to affect the processing of each new entry.
 Therefore, it is not necessary to incorporate "sliding window" techniques
 
\begin_inset CommandInset citation
LatexCommand citep
key "Vafaeipour2014"

\end_inset

 in our model, in contrast with similar works in the literature (Campos
 et al., 2011, 
\begin_inset CommandInset citation
LatexCommand citep
key "lcdcampos,Awchi"

\end_inset

.
 Often the use of Neural Networks involves the task of estimating a large
 number of hyper-parameters, related to their structure and performance.
 It is evident that to generate synthetic series it is necessary to adjust
 our model with the historical time series.
 We can formalize this problem as:
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references/refsjournal"
options "elsarticle-num-names"

\end_inset


\end_layout

\end_body
\end_document
