#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble

\author{
    Edson F. Luque Mamani\\
CLEI,2017\\
    University of San Agustin-University of Sao Paulo\\	
    edluquem@gmail.com\\	
  \and
    José Herrera Quispe\\
CLEI,2017\\
    University of San Agustin\\
    jherreraq@unsa.edu.pe
    
}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\lang spanish
Stochastic generation and forecasting of monthly hydrometeorological data
 based on non-traditional neural network
\end_layout

\begin_layout Abstract

\end_layout

\begin_layout Abstract

\lang spanish
The benefits of well-informed water management systems are related to the
 forecasting skills of hydrological variables.
 These benefits can be reflected in reducing economic and social losses
 to come.
 Therefore, the optimal design of water management projects frequently involves
 finding the methods or techniques that generate long sequences of hydrological
 data.
 These sequences considered as time series can be used to analyze and optimize
 the performance of the project designed.
 In order to cover these requirements, this work presents a new model of
 the stochastic process applied in problems that involve phenomena of stochastic
 behavior and periodic characteristics.
 Two components were used, the first one, a type of recurrent neural network
 relatively recent introduced in the literature and conceptually simple
 called ESN (echo state network) as the deterministic component, an interesting
 feature of ESN is that from certain algebraic properties, training only
 the output of the network is often sufficient to achieve excellent performance
 in practical applications.
 The second part of the model incorporates the uncertainty associated with
 hydrological processes, the model is finally called ESN-RNN.
 This model was calibrated with series of monthly discharge data of four
 different river basins from Mopex data set.
 Finally, a comparison was made between the performance of the ESN-RNN based
 model results, the results of the two feedforward neural networks ANN-1,
 ANN-2 using one and two past months respectively and Thomas–Fiering model.
 The results show that the ESN-RNN model represents a promising alternative
 for simulation purposes, with interesting potential in the context of hydromete
orological resources.
\end_layout

\begin_layout Keywords

\lang spanish
Echo state, forecasting, RNN.
\end_layout

\begin_layout Section

\lang spanish
Introduction
\end_layout

\begin_layout Standard

\lang spanish
In probability theory an stochastic process is defined as a set of models
 that allow the study of problems with random components.
 By observing phenomenon with random characteristics for a period of time,
 it is possible to obtain a trajectory of the observed process.
 When carrying out the same observation in a different period of time it
 is possible to obtain another trajectory, different from the first one.
 A stochastic process corresponds to the set of all possible trajectories
 that can be observed of this phenomenon.
 Each observed trajectory is called a time serie.
 Therefore, time serie is considered a realization of stochastic process.
 
\end_layout

\begin_layout Standard

\lang spanish
Natural phenomena such as precipitation and streamflow discharge have nonlinear,
 complex and chaotic characteristics, in order to model the behavior of
 these phenomena, initially linear approximation was used
\begin_inset CommandInset citation
LatexCommand cite
key "BOXANDJenKys"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LUNA2006"

\end_inset

.
 Afterwards were developed methods using self-correcting models 
\begin_inset CommandInset citation
LatexCommand cite
key "lcdcampos"

\end_inset

 such as the PAR(p) model 
\begin_inset CommandInset citation
LatexCommand cite
key "maceira2"

\end_inset

.
 However, these models are statistical and linear, which means that their
 application in time series of chaotic behavior such as hydrometeorological
 series, can not capture the actual characteristics of these series and
 therefore sometimes is found to be inadequate
\begin_inset CommandInset citation
LatexCommand cite
key "Raman95multivariatemodelling"

\end_inset

.
\end_layout

\begin_layout Standard

\lang spanish
Among approaches that attempt to model complex non-linear behavior, the
 Artificial Neural Networks (
\series bold
AN
\series default
N) are highlighted as machine learning methods in recent years, which may
 be adequate to deal with such problems.
 In fact, the
\series bold
 ANNs
\series default
 feedforward have been widely used in most research and applications in
 forecasting models in contrast to Recurrent Neural Networks(
\series bold
RNN
\series default
) 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

.
 The RNNs are able to represent dynamic non-linear maps commonly found in
 time series forecasting tasks
\begin_inset CommandInset citation
LatexCommand cite
key "lcdcampos"

\end_inset

.
 Studies about performance in forecasting of the recurrent neural network
 demostrate that they are better than their peers ANN in virtually all tests
\begin_inset CommandInset citation
LatexCommand cite
key "6327793"

\end_inset

.
 However, the main reason to prefer to use the feedforward neural networks
 over recurrent neural networks is that the later generates greater complexity,
 especially in the neural network training process.
 This motived the development of a stochastic process model using Recurrent
 Artificial Neural Networks in order to take advantage of its aforementioned
 characteristics.
 this was possible using an approach called Reservoir Computing (RC)
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

.
 Reservoir Computing is a training approach that is emerging as simple and
 fast compared to other approaches used in traditional recurrent ANNs, all
 in order to reduce complexity and leverage its proven ability to represents
 time series characteristics better.
 In addition, as part of our proposed model will be considered a non-determinist
ic component representing noise with a normal distribution in order to take
 into account the uncertainty that normally affects natural processes 
\begin_inset CommandInset citation
LatexCommand cite
key "Awchi"

\end_inset

.
 Being our model a new proposal in the literature.
 Finally, as a case study, it was chosen to apply this model on well-known
 Model Parameter Estimation Experiment (MOPEX) data set
\begin_inset CommandInset citation
LatexCommand cite
key "Duan20063"

\end_inset

.
 
\end_layout

\begin_layout Section
History and developments
\end_layout

\begin_layout Standard
The nonstationary nature of the precipitation and streamflow time series
 is considered one of the most important difficulties to forecast
\begin_inset CommandInset citation
LatexCommand cite
key "4371334"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Awchi"

\end_inset

.
 Initial auto-regressive models, as well as models based on Box & Jenkis
 methodology were used in forecasting problems, for example in 
\begin_inset CommandInset citation
LatexCommand cite
key "Peng2010"

\end_inset

 the author shows that there is no evidence that multivariate AR(1) models
 are inadecuate as predictors.
 Studies such as 
\begin_inset CommandInset citation
LatexCommand cite
key "JAWR:JAWR70A"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Thomas"

\end_inset

 describe mathematical models, which can reproduce special characteristics
 such as periodicity and consider the effects of linear correlation.
 In fact, the non-deterministics concept considered as part of our model
 was based on Thomas and Fierinig work
\begin_inset CommandInset citation
LatexCommand cite
key "Thomas"

\end_inset

.
 All these studies propose that natural behavior of times series can be
 simulated by a simple linear relationship with previous data.
 
\end_layout

\begin_layout Standard
The problem with previous models is that tasks like forecasting are naturally
 dynamics.
 For this reason artificial intelligence methods have been appearing as
 alternatives with good performance as predictors of time series.
 Works suchs 
\begin_inset CommandInset citation
LatexCommand cite
key "WRCR:WRCR9735"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "WRCR:WRCR11667"

\end_inset


\lang spanish

\begin_inset CommandInset citation
LatexCommand cite
key "lcdcampos"

\end_inset


\lang american
 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-20-1405-2016"

\end_inset

 used Artificial Neural Networks (ANN) as forecasting models.
 The Recurrent Neural Networks demostrated better capacity than ANN feeddorward
 due their structure
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

, which allow a more parsimonious modeling of dynamic properties.
 However, it was also demostrated that the recurrence present in its structure
 can cause increce of training conplexity and subsequently cause problems
 of convergence 
\begin_inset CommandInset citation
LatexCommand cite
key "1"

\end_inset

.
 By 2000 the concept of Reservoir Computing (RC) was introduced.
 Reservoir Computing is a training approach that can be remarkably simpler
 and faster than those traditional applied in RNN, according to 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

 few applications of RC in hydrometereology have been made: in 
\begin_inset CommandInset citation
LatexCommand cite
key "en81012228"

\end_inset

, the most popular reservoir computing model named echo state networks (ESN)
 was used with a bayesian regularization for forecast short-term energy
 production of small hydroelectric plants, results indicate that the proposed
 model surpasses both RNN's feedforward and ESN in its simple version.
 Similar works such as 
\begin_inset CommandInset citation
LatexCommand cite
key "Coulibaly201076"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Abrahart201276"

\end_inset

 used ESN to forecast monthly water levels for the four Great Lakes of North
 America, the authors demostrated the good performance of ESN networks and
 attributed it to their highly non-linear and dynamic structure.
 The echo state network are found to be valid alternatives to traditional
 recurrent ANNs in water inflow, for exampel in 
\begin_inset CommandInset citation
LatexCommand cite
key "4371334"

\end_inset

 where the performance of ESN is compared with SONARX
\begin_inset CommandInset citation
LatexCommand cite
key "4371335"

\end_inset

, RBF networks and ANFIS model
\begin_inset CommandInset citation
LatexCommand cite
key "256541"

\end_inset

, and 
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

 where the predictive capacity of ESN models are evaluated on a variety
 of large-scale basins.
 Experiments are carried out by comparing three different ESN variations
 with two RNN models feedforward.
 In addition, several aspects of ESN's design are investigated in order
 to optimize hydrologically relevant information.
 Only 
\begin_inset CommandInset citation
LatexCommand cite
key "en81012228"

\end_inset

 presents a hybrid system as our model proposal, this study consider two
 components; A deterministic (Recurrent ANN using ESN) and non-deterministic
 component ( random noise), in order to take advantage that a hybrid system
 can provide us in forecasting task.
\end_layout

\begin_layout Standard
Section 3 and 4 briefly reviews feedforward and traditional recurrent ANN
 models and their training methods, after which a short introduction to
 RC is given and ESN is described more detailed.
 Section 5 presents the proposal model used in this work.
 The results of some experiments are presented and discussed in Sect.
 6, and finally conclusions are drawn in Sect.
 7.
\end_layout

\begin_layout Section
Recurrent Neural Networks 
\end_layout

\begin_layout Standard
Recurrent neural networks (RNNs) are a subclass of ANNs represented by cyclic
 graph in its structure.
 These directed cycles accumulate previous activity that allows the network
 to store an internal state and consequently process sequences of inputs
 in order to perform temporal tasks, by this reason there is no need to
 feed the network with history of previous inputs and outputs like in Time-Delay
 Neural Network 
\begin_inset CommandInset citation
LatexCommand cite
key "Kuna2015"

\end_inset

.
 Therefore, prediction of future process output can be described as: 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $Output_{t+1}\cong Forecasting\left(RNNstate,Input_{t},Output_{t}\right)$
\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:elmanandwilliam"

\end_inset

 b) and a) show the two types of traditional recurrent ANN models , the
 Elman recurrent network 
\begin_inset CommandInset citation
LatexCommand cite
key "Elman90findingstructure"

\end_inset

 and the Willians- Zipser fully recurrent network 
\begin_inset CommandInset citation
LatexCommand cite
key "Williams:1989:LAC:1351124.1351135"

\end_inset

.
 Both networks have cyclical connections in their structure, in a) the input
 conects directly to all neurons include output one, hidden and output neurons
 are fully interconnected.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/RNNewilliamandelman.pdf
	lyxscale 30
	scale 10

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:elmanandwilliam"

\end_inset

(b) Elman recurrent ANN.
 a) William-zipser fully recurrent ANN
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Training Algorithms
\end_layout

\begin_layout Standard
Supervised training is probably the most common approach used among the
 current types of neural network systems, in order to adjust the network
 weight matrix 
\series bold
W,
\series default
 samples with inputs and outputs are used in the network for later optimisation
 algorithms attempt to minimise output error.
 A well known training method is the standard backpropagation algorithm
 (BP)
\begin_inset CommandInset citation
LatexCommand cite
key "Rumelhart:1986:PDP:104279"

\end_inset

, which is a kind of gradient descent technique where local minimum is approache
d by changing weights along the direction of negative error gradient.
 The objective function E(W) is calculated after BP applies an update to
 the weights in the network;
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle\omega_{ji}=-\eta\frac{\partial E}{\partial\omega_{ji}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\eta$
\end_inset

 is constant positive value called learning rate.
 Previous weigth change called momentum rate 
\begin_inset Formula $\beta$
\end_inset

 can be added to the current weight change, this often speeds up the learning
 process
\begin_inset CommandInset citation
LatexCommand cite
key "Sutskever2013"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle\omega_{ji}^{'}=\beta\triangle\omega_{ji}-\eta\frac{\partial E}{\partial\omega_{ji}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Weigth updates can be performed in online mode or based on the mean error
 over all training data, that is called batch mode.
 Beside more sophisticated alternatives to the BP algorithm, such as the
 Levenberg-Marquardt(LM) have been found faster convergence algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "hess-9-111-2005"

\end_inset

.
 In this algorithm the weight update is obtained by the following equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\varDelta\omega=-\left[H+\mu I\right]^{-1}J^{T}\rho
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\mu$
\end_inset

 is a learning rate, 
\series bold
J 
\series default
the jacobian matrix, which contains the first derivatives of the network
 error with respect to the weights and biases, and 
\begin_inset Formula $\rho$
\end_inset

 is a vector of network errors.
 Finally, 
\series bold
H 
\series default
an aproximation of the Hessian matrix.
\end_layout

\begin_layout Section*
Recurrent ANN training
\end_layout

\begin_layout Standard
Standard BP algorithm is not suited for networks with cycles in them.
 Nonetheless, applynig some artifices we can see a RNN like a feedforward
 network by unfolding the RNN network in time as shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:unfold"

\end_inset

, where the recurrent network is just a layered net that keeps reusing the
 same weigths, we assume a time delay of 1 in using each connection, creating
 an equivalent feedforward network
\begin_inset CommandInset citation
LatexCommand cite
key "Williams90anefficient"

\end_inset

, this extension of the BP method is called backpropagation through time(BPTT).
 in BPTT the number of networks copies is equal to time step 
\series bold
T.
 
\series default
It would be impractical in online manner, since its memory footprint grows
 linearly with time.
 Therefore, the network unfoldig is limited to a chosen truncation depth
 to keep the method feasible
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/RNNunfoldprocess.pdf
	lyxscale 30
	scale 12

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:unfold"

\end_inset

recurrent network unfolded in time.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
More sofisticated methods were developed to overcome limitatitons of BPTT,
 for example Real-Time Recurrent Learning
\begin_inset CommandInset citation
LatexCommand cite
key "Williams:1989:LAC:1351124.1351135"

\end_inset

, Clockwork Recurrent Network (CW-RNN) that splits hidden layer into M modules
 running at different clocks
\begin_inset CommandInset citation
LatexCommand cite
key "Kuna2015"

\end_inset

 and the extended Kalman filter(EKF) method, which each time estimates optimal
 weights, given a series of observed ouputs, for details see
\begin_inset CommandInset citation
LatexCommand cite
key "Sum:1998:EKF:296468.296482"

\end_inset

.
 However, even the methods such the later, suffers from shortcomings related
 with model complexity and optimisation (gradient)
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

, i.e., many updates may be necessary it could be computationally expensive,
 the gradient information might becomes useless by weight updates procedure
\begin_inset CommandInset citation
LatexCommand cite
key "doya1992bifurcations"

\end_inset

.
\end_layout

\begin_layout Section*
Echo State Network
\end_layout

\begin_layout Standard
Echo state network(ESN) is a reservoir computing model has been introduced
 by Jaeger 
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

 in order to addresing the dificulties in RNN training.
 Basically ESN is a clever way to train a RNN where a "reservoir" of hidden
 units are sparsely connected to each other and the inputs are connected
 to this reservoir, the hidden conections are not trained, they are randomly
 initialized.
 The state of the dynamical reservoir is called "echo states", these states
 can be undertood as an "echo" generated by the input history.
 The output layer is connected to the hidden reservoir 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Echo-State-Network"

\end_inset

.
 The interesting property of ESNs is that while the recurrent topology has
 fixed connections, only the linear readout is trained and extracts the
 desired response from the reservoir’s state.
 The idea behind this is that the reservoir contains a representation of
 current and historical system dynamics that is rich enough to enable the
 readout to learn the functional dependence between inputs and outputs
\begin_inset CommandInset citation
LatexCommand cite
key "hess-17-253-2013"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/ESNstructure.pdf
	lyxscale 30
	scale 10

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Echo-State-Network"

\end_inset

Echo State Network
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
According to the notation used in 
\begin_inset CommandInset citation
LatexCommand cite
key "4371334"

\end_inset

 the activation of the internal echo states is updated follow the equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x\left(n+1\right)=f\left(\mathbf{W}^{in}u\left(n\right)+\mathbf{W}x\left(n\right)\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where
\series bold
 
\begin_inset Formula $u(n)$
\end_inset


\series default
 is the input signal
\series bold
, 
\series default

\begin_inset Formula $\mathbf{W}^{in}$
\end_inset

 are the weights between the input and the internal states
\series bold
, W 
\series default
is the recurrent connection weight matrix, and 
\begin_inset Formula $x(n)$
\end_inset

 is the echo state vector.
 Finally, 
\begin_inset Formula $f$
\end_inset

 is the activation function of internal units(linear or hyperbolic tangent
 function).
 
\end_layout

\begin_layout Standard
The "echo state property" is a condition needed to scale the reservoir weight
 matrix W, this condition asserts that recurrent network states are strongly
 coupled with the input history, this is defined in term of the spectral
 radius ( largest absolute eigenvalue of W) 
\begin_inset Formula $\rho$
\end_inset

(W)<1, this condition is generally satisfied 
\begin_inset CommandInset citation
LatexCommand cite
key "Jaeger78"

\end_inset

.
\end_layout

\begin_layout Standard
The optimal output weights 
\begin_inset Formula $W^{out}$
\end_inset

 for the output connections can be found by multiplying the pseudo inverse
 with the target output 
\begin_inset Formula $Y^{target}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
W^{out}=Y^{target}X^{+}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $X$
\end_inset

 is the collected states matrix of the ESN, this matrix contains the activation
 of the reservoir for each training input:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
X^{+}=\left(XX^{T}\right)^{-1}X^{T}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The output 
\begin_inset Formula $y(n)$
\end_inset

 is then computed with equation :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y(n)=W^{out}x(n)
\end{equation}

\end_inset


\end_layout

\begin_layout Section
Hidrometereological data generation using ESN-RNN with random component
\end_layout

\begin_layout Standard
The proposed model is a mixed stochastic deterministic model for hydrological
 synthetic data generation, in terms of monthly series of 
\lang spanish
precipitation and streamflow discharge
\lang american
 using ESN-RNN.
 The model consists of two components; the first component is the stochastic
 part of Thomas-Fiering model
\begin_inset CommandInset citation
LatexCommand cite
key "Thomas"

\end_inset

, 
\begin_inset Formula $T_{v,t+1}$
\end_inset

 :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T_{v,t+1}=\epsilon_{v,t}S_{t+1}\sqrt{1-r_{t}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where, 
\begin_inset Formula $\epsilon_{v,t}$
\end_inset

 is a random normal deviate with zero mean and unit variance, 
\begin_inset Formula $s_{t+1}$
\end_inset

 represents the standard deviation of the normalized and standardized precipitat
ion and discharge in the 
\begin_inset Formula $t+1^{th}$
\end_inset

months and 
\begin_inset Formula $r_{t}$
\end_inset

 the correlation coefficient between data in the 
\begin_inset Formula $t^{th}$
\end_inset

and 
\begin_inset Formula $\left(t+1\right)^{th}$
\end_inset

months.
\end_layout

\begin_layout Standard
The second component 
\begin_inset Formula $E_{v,t}$
\end_inset

 is the deterministic component which is represented by the ESN-RNN architecture.
 The model can be resumed as the sum of both components above:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
H_{v,t}=f(E_{v,t}+T_{v,t})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $H_{v,t}$
\end_inset

 is the synthetic value obtained by our model.
 The function 
\begin_inset Formula $f$
\end_inset

 is the inverse of preprocessing transformations defined in equations 10
 and 12: 
\end_layout

\begin_layout Subsubsection*
Data preprocessing input and output 
\end_layout

\begin_layout Standard
In probability theory and statistical applied to hydrologic time series
 a basic assumption is which the variables, have to be normally distributed.
 Therefore, a transformation is required if time series do not meet this
 basic assumption.
 The operation needed is called seasonal standardization or deseasonalizing
 (normally distributed variables with zero-mean and unit standad deviation)
\begin_inset CommandInset citation
LatexCommand cite
key "Awchi"

\end_inset

.
\end_layout

\begin_layout Standard
The series of MOPEX data set for the period of january, 1948 to 2000 from
 4 river basins (see table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:riverbasin"

\end_inset

)were employed in this study.
 They needed a transformation to reduce their biased skewness, the skewness
 coefficient observerd was reduced using log-transformation written as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
X_{v,t}=\log\left(H_{v,t}+c_{t}\overline{H_{t}}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
c_{t}=\frac{a}{g_{t}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where, 
\begin_inset Formula $H_{v,t}$
\end_inset

 is monthly observed data for month 
\begin_inset Formula $t(t=1,….,12)$
\end_inset

 and year 
\begin_inset Formula $v(ν=1,….,N)$
\end_inset

, 
\begin_inset Formula $N$
\end_inset

 is number of years of record of the series, 
\begin_inset Formula $\bar{H_{t}}$
\end_inset

 is monthly average inflow for month 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $a$
\end_inset

 is a constant, for this study the value adopted was 0.8 resulted by trial
 and error data test, 
\begin_inset Formula $g_{t}$
\end_inset

 is the skewness coefficient for the set 
\begin_inset Formula $H_{1,t},H_{2,t},...,H_{N,t}$
\end_inset

 and 
\begin_inset Formula $X_{v,t}$
\end_inset

 are the normalized data, for year 
\begin_inset Formula $v$
\end_inset

 and month 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
The data used by stochastic component (Thomas-Fiering model) were standardized
 in monthly basis through:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Y_{v,t}=\frac{X_{v,t}-\bar{X_{t}}}{S_{t}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Y_{v,t}$
\end_inset

 is standardized value for month 
\begin_inset Formula $t$
\end_inset

 and year 
\begin_inset Formula $v$
\end_inset

.
 
\begin_inset Formula $\bar{X}_{t}$
\end_inset

 and 
\begin_inset Formula $S_{t}$
\end_inset

 are mean and standard deviation for month 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:riverbasin"

\end_inset

characteristic of four Mopex river basins
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top" width="1cm">
<column alignment="center" valignment="top" width="1cm">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mopex id
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
River
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Area(km2)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean Annual precip(mm)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean Annual discharge(mm)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3179000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bluestone
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1020
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1018
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
421
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3364000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
East Fork White
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4421
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
855
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
376
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3054500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tygart Valley
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2372
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1166
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
745
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1541500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Clearfield Creek
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2170
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
827
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
179
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Neural network architectures
\end_layout

\begin_layout Standard
The performance of this approach is compared with three models, two based
 on feedforward ANN and once statistical model such as Thomas and Fiering,
 usually the models mentioned above require previous measured samples which
 must be considered as input data, Therefore, the first model (ANN-1) generates
 hidrological data for the present month using the data of past month, the
 second model (ANN-2) use two previous months in order generates data for
 present month.
 
\end_layout

\begin_layout Standard
A three-layer feedforward architecture is adopted in ANN-1 and ANN-2, and
 tan-sigmoid functions were used as activation function for which output
 falls in the range of 
\begin_inset Formula $\left[-1,+1\right]$
\end_inset

.
 The number of hidden layer nodes was decided by trial and error procedure.
 
\end_layout

\begin_layout Standard
Since feedback connections in the ESN-RNN architecture develop a type of
 internal memory, it is not necessary an input signal before further processing.
 Was considerated the input and bias fully connected to the reservoir, The
 weights of the input to reservoir connection were randomly selected from
 a uniform distribution where 
\series bold

\begin_inset Formula $W^{in}$
\end_inset


\series default
 
\begin_inset Formula $\in$
\end_inset

 
\begin_inset Formula $\left[-0.1,0.1\right]$
\end_inset

.
 All other connection weights were selected from a normal distribution.
 A sparsely and randomly connected reservoir was used.
\end_layout

\begin_layout Standard
The number of the internal units of the reservoir and the spectral radious
 of the reservoir weights are important settings for a ESN model
\begin_inset CommandInset citation
LatexCommand cite
key "LukoseviciusJaeger09"

\end_inset

.
 By this reason a respectively training performance study for each 4 river
 basin over values of spectral radious from 0.1 to 0.9 and the size of reservoir
 was made, see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ESN-training-performance"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:ESN-training-performance"

\end_inset

4 rivers ESN training performance, Rmse (y-axis) vs Reservoir size(x-axis),
 all over a range of values for the spectral radius from 0.1 to 0.9 (over
 5 runs).
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/esntraining.pdf
	scale 40

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
From Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ESN-training-performance"

\end_inset

 we can see that the bigger size of reservoirs generate lower performance
 in training ESN-RNN for the 4 basins selected, each river basin was assigned
 with specific reservoir size(red points) and spectral radious(highlighted
 in blue), this is because the characteristics and dynamic nature of the
 river are different.
 
\end_layout

\begin_layout Subsection
Evaluation of the Performance of Models
\end_layout

\begin_layout Standard
In this study, 200 syntetics series were generated with length of 24 months
 (2 years), The data were split up into training (1948–1999), and test (1998–200
0).
 The performance of the forecasting models was evaluated according to three
 error criteria: Normalized Root Mean Square Error (NRMSE), Mean Absolute
 Error (MAD), and Mean Percentage Error (MPE).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:bluestone"

\end_inset

Testing Patterns (1998 - 2000): 
\lang spanish
Streamflow discharge
\lang american
 of Bluestone river
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/tygarsintetic.pdf
	scale 35

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:tygersintetic"

\end_inset

Testing Patterns (1998 - 2000): 
\lang spanish
Streamflow discharge
\lang american
 of Tygar Valley river
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/bluestone.pdf
	scale 35

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:eastforwhite"

\end_inset

Testing Patterns (1998 - 2000): 
\lang spanish
Streamflow discharge
\lang american
 of East Fork White river
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/eastforwhite.pdf
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Results and Discussion
\end_layout

\begin_layout Standard
The models used here were trained and adjusted: ANN1, ANN2, Thomas-Fiering
 and ESN-RNN.
 During both the training and testing periods of the ESN, the entries of
 
\series bold
W
\series default
 were scaled with different espectral values for the 4 river basins see
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ESN-training-performance"

\end_inset

.
 In order to avoid an initial contamination, we have disregarded first responses
(states) of reservoir.
 The number of hidden layer processing elements was defined as N1 = 17,
 N2= 20,N3 = 22, N4= 25, which presented best results for each 4 river basins,
 see red points in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ESN-training-performance"

\end_inset

.
\end_layout

\begin_layout Standard
We note that ESN states have a wide dynamic range in this problem, when
 it would be necessary to cover the feature space during the whole training
 period.
 Those variety ESN states represent a set of functional bases constructed
 dynamically by the input, while the readout simply projects the desired
 response onto this representation space.
 
\end_layout

\begin_layout Standard
We can see, at Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:bluestone"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:tygersintetic"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:eastforwhite"

\end_inset

, the result of the generate synthetic data by ESN-RNN and Thomas fiering
 models, of discharge for 3 river basins respectively.
 The blue line refers to the observed measures of this time series, and
 the black lines refers to the “forecasted” series of streamflow discharge(mm)
 to the period of 1998-2000.
 
\end_layout

\begin_layout Standard
Based on section a.1, b.1 of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:bluestone"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:tygersintetic"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:eastforwhite"

\end_inset

, we can say the predictor model was able to learn and capture most of the
 behavior variability present on this time series, lower variability, indicate
 that the training had a desired effect in order capture the dynamic of
 hidrological series.
 which seems but is not a easy task for any predictor.
 The ESN-RNN predictor presented good results.
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:error"

\end_inset

 shows the forecasting errors obtained by the models used and compared in
 this paper: ESN-RNN, ANN-1,ANN-2 and Thomas -Fiering.
 We can see that ESN-RNN, and models based on no-recurrent neural networks(ANN-1
 and ANN-2) performed better than Thomas-Fiering model, which is a pure
 stochastic model.
 In addition, we note that ANN-1 and ANN-2 models presented practically
 the same performance.
 Moreover, the ESN-RNN model performed few better than all other models,
 even though it presents a significantly simpler, and faster, training algorithm.
 This fact prove how powerful and promising is this approach.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:error"

\end_inset

 Forescasting error for 4 Mopex river basins 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="17" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ID River
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Models
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NRMSE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MAD
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MPE(%)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3054500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESN-RNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.67
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.91
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
296.91
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.72
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.02
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
356.34
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.70
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
330.23
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thomas-Fiering 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.78
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
402.00
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3364000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESN-RNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.54
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
91.93
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.34
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.61
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
93.56
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.59
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
93.24
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thomas-Fiering 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.32
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.62
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
95.89
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3179000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESN-RNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.62
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.56
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
169.79
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.75
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.66
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
180.56
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.80
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.70
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
195.43
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thomas-Fiering 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.83
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.79
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
257.58
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1541500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ESN-RNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.70
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.51
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
92.15
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.80
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.59
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
111.13
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ANN-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.79
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.65
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
109.98
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Thomas-Fiering 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.95
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.65
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
126.37
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
A model is proposed as an alternative and effective tool for generation
 of monthly hydrological streamflow series.
 The model consists basically of a deterministic component defined in terms
 of a Recurrent neural network trained wit ESN in addition to a stochastic
 component which includes a white noise module.
 Historical monthly data were used to train and test the ability of the
 model for streamflow data generation and forecasting.
 
\end_layout

\begin_layout Standard
This study presents a type of recurrent neural network called Echo State
 Network (ESN), which possesses a highly interconnected and recurrent topology.
 The ESN has two interesting properties: one is that only the readout is
 trained, whereas the recurrent topology has fixed connection weights; and
 another one is that ESN has internal built-in memory resulting from the
 feedback connections, it is not necessary to embed the input signal before
 further processing.
 Here, the ESN is used to forecast streamflow.
 A database of average monthly streaming inflows of project Mopex was used
 as source of training and test data.
\end_layout

\begin_layout Standard
For comparison, the Thomas-Fiering model was applied.
 The proposed hybrid model is also tested using two neural networks architecture
s, the first architecture (ANN-1) utilizes one previous month’s streamflow,
 and the second (ANN-2) utilizes two previous months, in order to get the
 output of the model which is the next month.
 The results show that the our model demonstrates a little better in performance
 compared to ANN-1, ANN-2 and Thomas-Fiering models.
 In addition the results also revealed that the proposed model performs
 little better comparing with the pure stochastic Thomas-Fiering Model,
 The syntetic series produced by the Recurrent NN (ESN), they present low
 variability and outliers in contrast with Thomas-Fiering Model, indicating
 that the use of Recurrent NN features had the desired effect.
 It can be concluded that the proposed model is a promising alternative
 to be considered for more applications, competing with other linear pure
 stochastic autoregressive, traditional neural networks models.
 Without forgetting to mention that the specific architecture of ESN models
 overcomes several important drawbacks to traditional recurrent methods.
 This approach can lead to more accurate, reliable, and realistic models.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references/refs"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
